{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model \n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "X = np.load(\"training_data/sequences.npy\")\n",
    "y = np.load(\"training_data/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1572, 30, 1662)\n",
      "X_test:  (278, 30, 1662)\n"
     ]
    }
   ],
   "source": [
    "#try scaling for real time performance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling dataset between epochs\n",
    "buffer_size = 10000\n",
    "batch_size = len(X_train) // 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "log_dir = os.path.join('logs')\n",
    "checkpoint_dir = os.path.join('models/checkpoints/')\n",
    "tb_callback = TensorBoard(log_dir = log_dir)\n",
    "reduceLR_callback = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.8, cooldown = 10, min_lr = 1e-5)\n",
    "checkpoint_callback = ModelCheckpoint(filepath = checkpoint_dir, monitor = 'val_accuracy', save_best_only = True, save_weights_only = True, initial_value_threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM model:\n",
    "i = Input(shape = X_train[0].shape)\n",
    "#choose b/w ReLU and tanh activation\n",
    "x = LSTM(128, return_sequences = True)(i) \n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dense(len(list(set(y))), activation = 'softmax')(x)\n",
    "\n",
    "LSTM_model = Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "33/33 [==============================] - 3s 42ms/step - loss: 3.6377 - accuracy: 0.0312 - val_loss: 3.6200 - val_accuracy: 0.0324 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 3.6215 - accuracy: 0.0280 - val_loss: 3.6155 - val_accuracy: 0.0216 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 3.6087 - accuracy: 0.0267 - val_loss: 3.6083 - val_accuracy: 0.0108 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 3.5918 - accuracy: 0.0490 - val_loss: 3.5847 - val_accuracy: 0.0576 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 3.5796 - accuracy: 0.0369 - val_loss: 3.5445 - val_accuracy: 0.0504 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 3.5014 - accuracy: 0.0668 - val_loss: 3.4673 - val_accuracy: 0.0324 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 3.3669 - accuracy: 0.0757 - val_loss: 3.2297 - val_accuracy: 0.1007 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 3.1754 - accuracy: 0.0859 - val_loss: 3.0177 - val_accuracy: 0.0863 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 2.9529 - accuracy: 0.1164 - val_loss: 2.9288 - val_accuracy: 0.1223 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 2.8220 - accuracy: 0.1330 - val_loss: 2.7362 - val_accuracy: 0.1403 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 2.7222 - accuracy: 0.1228 - val_loss: 2.6438 - val_accuracy: 0.1583 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 2.6168 - accuracy: 0.1489 - val_loss: 2.5386 - val_accuracy: 0.2302 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 2.5524 - accuracy: 0.1807 - val_loss: 2.4545 - val_accuracy: 0.2410 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 2.4808 - accuracy: 0.1883 - val_loss: 2.4530 - val_accuracy: 0.2050 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 2.4759 - accuracy: 0.1921 - val_loss: 2.3523 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 2.4017 - accuracy: 0.2150 - val_loss: 2.2993 - val_accuracy: 0.2950 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2.3564 - accuracy: 0.2207 - val_loss: 2.2512 - val_accuracy: 0.2914 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 2.2905 - accuracy: 0.2405 - val_loss: 2.2407 - val_accuracy: 0.2806 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2.2493 - accuracy: 0.2500 - val_loss: 2.1657 - val_accuracy: 0.3058 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 2.1806 - accuracy: 0.2818 - val_loss: 2.0818 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2.0926 - accuracy: 0.2964 - val_loss: 2.0324 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 2.0521 - accuracy: 0.3155 - val_loss: 1.9997 - val_accuracy: 0.3165 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 2.0169 - accuracy: 0.3257 - val_loss: 1.9345 - val_accuracy: 0.3777 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 2.0230 - accuracy: 0.3073 - val_loss: 2.0507 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.9466 - accuracy: 0.3397 - val_loss: 1.8155 - val_accuracy: 0.3849 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.9041 - accuracy: 0.3346 - val_loss: 1.9027 - val_accuracy: 0.3417 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.9195 - accuracy: 0.3397 - val_loss: 1.8160 - val_accuracy: 0.3669 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1.7995 - accuracy: 0.3760 - val_loss: 1.6985 - val_accuracy: 0.4353 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 1.7415 - accuracy: 0.3880 - val_loss: 1.7256 - val_accuracy: 0.4137 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 1.7070 - accuracy: 0.3989 - val_loss: 1.8469 - val_accuracy: 0.3345 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.8075 - accuracy: 0.3753 - val_loss: 1.8499 - val_accuracy: 0.3741 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.7386 - accuracy: 0.3950 - val_loss: 1.5827 - val_accuracy: 0.4856 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.6293 - accuracy: 0.4230 - val_loss: 1.6573 - val_accuracy: 0.4029 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.6830 - accuracy: 0.4128 - val_loss: 1.6740 - val_accuracy: 0.3993 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.5857 - accuracy: 0.4275 - val_loss: 1.4875 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.5617 - accuracy: 0.4338 - val_loss: 1.5517 - val_accuracy: 0.4856 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1.5229 - accuracy: 0.4529 - val_loss: 1.4172 - val_accuracy: 0.5252 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.4921 - accuracy: 0.4618 - val_loss: 1.4400 - val_accuracy: 0.5036 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.4869 - accuracy: 0.4733 - val_loss: 1.4669 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.5851 - accuracy: 0.4230 - val_loss: 1.6203 - val_accuracy: 0.4245 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.5124 - accuracy: 0.4447 - val_loss: 1.4461 - val_accuracy: 0.4820 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.4395 - accuracy: 0.4809 - val_loss: 1.3893 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.4044 - accuracy: 0.5045 - val_loss: 1.3773 - val_accuracy: 0.5072 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 1.4318 - accuracy: 0.4796 - val_loss: 1.3671 - val_accuracy: 0.5288 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 1.3768 - accuracy: 0.4943 - val_loss: 1.4011 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1.3535 - accuracy: 0.5006 - val_loss: 1.2861 - val_accuracy: 0.5468 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1.2979 - accuracy: 0.5356 - val_loss: 1.2730 - val_accuracy: 0.5683 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.3432 - accuracy: 0.5076 - val_loss: 1.2856 - val_accuracy: 0.5504 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.3157 - accuracy: 0.5127 - val_loss: 1.2655 - val_accuracy: 0.5396 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.2562 - accuracy: 0.5324 - val_loss: 1.1788 - val_accuracy: 0.5863 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.2875 - accuracy: 0.5229 - val_loss: 1.2830 - val_accuracy: 0.5827 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.2431 - accuracy: 0.5490 - val_loss: 1.1801 - val_accuracy: 0.5863 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.2697 - accuracy: 0.5375 - val_loss: 1.2151 - val_accuracy: 0.5540 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.2675 - accuracy: 0.5191 - val_loss: 1.2445 - val_accuracy: 0.5180 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.2882 - accuracy: 0.5331 - val_loss: 1.2012 - val_accuracy: 0.5719 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.2266 - accuracy: 0.5598 - val_loss: 1.4368 - val_accuracy: 0.4532 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.1675 - accuracy: 0.5770 - val_loss: 1.1183 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.1637 - accuracy: 0.5840 - val_loss: 1.1440 - val_accuracy: 0.6007 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1.1800 - accuracy: 0.5700 - val_loss: 1.2955 - val_accuracy: 0.5612 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.2242 - accuracy: 0.5662 - val_loss: 1.0664 - val_accuracy: 0.6007 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.1843 - accuracy: 0.5553 - val_loss: 1.1985 - val_accuracy: 0.5899 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.1206 - accuracy: 0.5884 - val_loss: 1.1837 - val_accuracy: 0.5971 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.0927 - accuracy: 0.6075 - val_loss: 1.0618 - val_accuracy: 0.6439 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.0865 - accuracy: 0.6043 - val_loss: 1.1184 - val_accuracy: 0.6007 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.0982 - accuracy: 0.5973 - val_loss: 1.0846 - val_accuracy: 0.6295 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.1468 - accuracy: 0.5941 - val_loss: 1.0943 - val_accuracy: 0.6115 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.0635 - accuracy: 0.6164 - val_loss: 0.9731 - val_accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.0301 - accuracy: 0.6132 - val_loss: 0.9872 - val_accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.0383 - accuracy: 0.6247 - val_loss: 0.9982 - val_accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1.0138 - accuracy: 0.6330 - val_loss: 1.1062 - val_accuracy: 0.6223 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.0910 - accuracy: 0.5859 - val_loss: 1.0266 - val_accuracy: 0.6439 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.0410 - accuracy: 0.6342 - val_loss: 0.9633 - val_accuracy: 0.6942 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 1.0849 - accuracy: 0.6145 - val_loss: 0.9475 - val_accuracy: 0.6259 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.9750 - accuracy: 0.6469 - val_loss: 0.9521 - val_accuracy: 0.6331 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.9720 - accuracy: 0.6539 - val_loss: 0.9368 - val_accuracy: 0.6619 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.9885 - accuracy: 0.6310 - val_loss: 0.8735 - val_accuracy: 0.7050 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.9308 - accuracy: 0.6673 - val_loss: 0.8861 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.8898 - accuracy: 0.6813 - val_loss: 0.8576 - val_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.9626 - accuracy: 0.6469 - val_loss: 0.9080 - val_accuracy: 0.6871 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.9327 - accuracy: 0.6501 - val_loss: 0.8507 - val_accuracy: 0.6942 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.9078 - accuracy: 0.6826 - val_loss: 1.1683 - val_accuracy: 0.5612 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.9562 - accuracy: 0.6571 - val_loss: 0.9143 - val_accuracy: 0.7050 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.8785 - accuracy: 0.6908 - val_loss: 0.8884 - val_accuracy: 0.6871 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.9275 - accuracy: 0.6660 - val_loss: 0.9494 - val_accuracy: 0.6799 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.9237 - accuracy: 0.6743 - val_loss: 0.8309 - val_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.8622 - accuracy: 0.6947 - val_loss: 0.7983 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.8294 - accuracy: 0.7067 - val_loss: 0.8078 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.8347 - accuracy: 0.6959 - val_loss: 0.8018 - val_accuracy: 0.7410 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.8182 - accuracy: 0.7010 - val_loss: 0.7609 - val_accuracy: 0.7194 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.8195 - accuracy: 0.6953 - val_loss: 0.7882 - val_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.8406 - accuracy: 0.6915 - val_loss: 0.9758 - val_accuracy: 0.6727 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.8468 - accuracy: 0.6915 - val_loss: 0.7881 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.7861 - accuracy: 0.7156 - val_loss: 0.7639 - val_accuracy: 0.7518 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.8060 - accuracy: 0.7023 - val_loss: 0.7651 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.8197 - accuracy: 0.6927 - val_loss: 0.7449 - val_accuracy: 0.7590 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.7887 - accuracy: 0.7093 - val_loss: 0.8298 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.7586 - accuracy: 0.7296 - val_loss: 0.7287 - val_accuracy: 0.7590 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.7936 - accuracy: 0.7055 - val_loss: 1.0033 - val_accuracy: 0.6331 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.8685 - accuracy: 0.6711 - val_loss: 0.7527 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.7895 - accuracy: 0.7010 - val_loss: 0.8445 - val_accuracy: 0.6583 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.8625 - accuracy: 0.6826 - val_loss: 0.8226 - val_accuracy: 0.6763 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.7503 - accuracy: 0.7246 - val_loss: 0.7009 - val_accuracy: 0.7734 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.7256 - accuracy: 0.7360 - val_loss: 0.7508 - val_accuracy: 0.7626 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.7235 - accuracy: 0.7239 - val_loss: 0.7154 - val_accuracy: 0.7482 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.6663 - accuracy: 0.7678 - val_loss: 0.6750 - val_accuracy: 0.7734 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.7455 - accuracy: 0.7188 - val_loss: 0.6832 - val_accuracy: 0.8058 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.7492 - accuracy: 0.7328 - val_loss: 0.7269 - val_accuracy: 0.7302 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.6901 - accuracy: 0.7519 - val_loss: 0.6654 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.6805 - accuracy: 0.7532 - val_loss: 0.7310 - val_accuracy: 0.7482 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.7372 - accuracy: 0.7309 - val_loss: 0.6319 - val_accuracy: 0.8022 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.6709 - accuracy: 0.7576 - val_loss: 0.6744 - val_accuracy: 0.7698 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.6697 - accuracy: 0.7615 - val_loss: 0.7074 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.6901 - accuracy: 0.7519 - val_loss: 0.6713 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.6485 - accuracy: 0.7710 - val_loss: 0.6930 - val_accuracy: 0.7698 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.7143 - accuracy: 0.7284 - val_loss: 0.7322 - val_accuracy: 0.7302 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.6589 - accuracy: 0.7627 - val_loss: 0.7214 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.6950 - accuracy: 0.7455 - val_loss: 0.6899 - val_accuracy: 0.7626 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.6606 - accuracy: 0.7545 - val_loss: 0.6340 - val_accuracy: 0.8094 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.6794 - accuracy: 0.7475 - val_loss: 0.6810 - val_accuracy: 0.7590 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.6511 - accuracy: 0.7545 - val_loss: 0.6379 - val_accuracy: 0.7806 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.6277 - accuracy: 0.7729 - val_loss: 0.6820 - val_accuracy: 0.7374 - lr: 8.0000e-04\n",
      "Epoch 122/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.6057 - accuracy: 0.7831 - val_loss: 0.5935 - val_accuracy: 0.8201 - lr: 8.0000e-04\n",
      "Epoch 123/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.5900 - accuracy: 0.7983 - val_loss: 0.5665 - val_accuracy: 0.8453 - lr: 8.0000e-04\n",
      "Epoch 124/1000\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.5835 - accuracy: 0.7964 - val_loss: 0.6554 - val_accuracy: 0.7806 - lr: 8.0000e-04\n",
      "Epoch 125/1000\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.6768 - accuracy: 0.7513 - val_loss: 0.6686 - val_accuracy: 0.7698 - lr: 8.0000e-04\n",
      "Epoch 126/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.6004 - accuracy: 0.7799 - val_loss: 0.5722 - val_accuracy: 0.8309 - lr: 8.0000e-04\n",
      "Epoch 127/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.6194 - accuracy: 0.7704 - val_loss: 0.5809 - val_accuracy: 0.8345 - lr: 8.0000e-04\n",
      "Epoch 128/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.5832 - accuracy: 0.7850 - val_loss: 0.5815 - val_accuracy: 0.7986 - lr: 8.0000e-04\n",
      "Epoch 129/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.5683 - accuracy: 0.7964 - val_loss: 0.5929 - val_accuracy: 0.8237 - lr: 8.0000e-04\n",
      "Epoch 130/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.5682 - accuracy: 0.7939 - val_loss: 0.8786 - val_accuracy: 0.7014 - lr: 8.0000e-04\n",
      "Epoch 131/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.6746 - accuracy: 0.7576 - val_loss: 0.5786 - val_accuracy: 0.8022 - lr: 8.0000e-04\n",
      "Epoch 132/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.5553 - accuracy: 0.7939 - val_loss: 0.6049 - val_accuracy: 0.7842 - lr: 8.0000e-04\n",
      "Epoch 133/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5628 - accuracy: 0.7824 - val_loss: 0.5660 - val_accuracy: 0.8381 - lr: 8.0000e-04\n",
      "Epoch 134/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5436 - accuracy: 0.8047 - val_loss: 0.5358 - val_accuracy: 0.8058 - lr: 8.0000e-04\n",
      "Epoch 135/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.5588 - accuracy: 0.7945 - val_loss: 0.5282 - val_accuracy: 0.8453 - lr: 8.0000e-04\n",
      "Epoch 136/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.5248 - accuracy: 0.8155 - val_loss: 0.5804 - val_accuracy: 0.7986 - lr: 8.0000e-04\n",
      "Epoch 137/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.5481 - accuracy: 0.8060 - val_loss: 0.5668 - val_accuracy: 0.7986 - lr: 8.0000e-04\n",
      "Epoch 138/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5245 - accuracy: 0.8092 - val_loss: 0.6998 - val_accuracy: 0.7842 - lr: 8.0000e-04\n",
      "Epoch 139/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.5337 - accuracy: 0.8136 - val_loss: 0.5714 - val_accuracy: 0.8165 - lr: 8.0000e-04\n",
      "Epoch 140/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.5343 - accuracy: 0.8162 - val_loss: 0.5567 - val_accuracy: 0.8381 - lr: 8.0000e-04\n",
      "Epoch 141/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.5402 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.8525 - lr: 8.0000e-04\n",
      "Epoch 142/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5914 - accuracy: 0.7971 - val_loss: 0.5859 - val_accuracy: 0.7878 - lr: 8.0000e-04\n",
      "Epoch 143/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5875 - accuracy: 0.7882 - val_loss: 0.5840 - val_accuracy: 0.8058 - lr: 8.0000e-04\n",
      "Epoch 144/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.5544 - accuracy: 0.7983 - val_loss: 0.8595 - val_accuracy: 0.7194 - lr: 8.0000e-04\n",
      "Epoch 145/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5952 - accuracy: 0.7735 - val_loss: 0.5068 - val_accuracy: 0.8561 - lr: 8.0000e-04\n",
      "Epoch 146/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5426 - accuracy: 0.7977 - val_loss: 0.5716 - val_accuracy: 0.8273 - lr: 8.0000e-04\n",
      "Epoch 147/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5489 - accuracy: 0.7901 - val_loss: 0.5747 - val_accuracy: 0.7770 - lr: 8.0000e-04\n",
      "Epoch 148/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.5841 - accuracy: 0.7780 - val_loss: 0.5370 - val_accuracy: 0.8273 - lr: 8.0000e-04\n",
      "Epoch 149/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.5087 - accuracy: 0.8187 - val_loss: 0.5196 - val_accuracy: 0.8273 - lr: 8.0000e-04\n",
      "Epoch 150/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.5293 - accuracy: 0.8142 - val_loss: 0.5082 - val_accuracy: 0.8633 - lr: 8.0000e-04\n",
      "Epoch 151/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.5204 - accuracy: 0.8181 - val_loss: 0.4920 - val_accuracy: 0.8561 - lr: 8.0000e-04\n",
      "Epoch 152/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.5004 - accuracy: 0.8193 - val_loss: 0.5486 - val_accuracy: 0.8094 - lr: 8.0000e-04\n",
      "Epoch 153/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.6933 - accuracy: 0.7462 - val_loss: 0.5900 - val_accuracy: 0.7950 - lr: 8.0000e-04\n",
      "Epoch 154/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.5222 - accuracy: 0.8022 - val_loss: 0.5049 - val_accuracy: 0.8417 - lr: 8.0000e-04\n",
      "Epoch 155/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4930 - accuracy: 0.8302 - val_loss: 0.5244 - val_accuracy: 0.8273 - lr: 8.0000e-04\n",
      "Epoch 156/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.5044 - accuracy: 0.8149 - val_loss: 0.5034 - val_accuracy: 0.8489 - lr: 8.0000e-04\n",
      "Epoch 157/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.4960 - accuracy: 0.8206 - val_loss: 0.4864 - val_accuracy: 0.8597 - lr: 8.0000e-04\n",
      "Epoch 158/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.5052 - accuracy: 0.8200 - val_loss: 0.4964 - val_accuracy: 0.8381 - lr: 8.0000e-04\n",
      "Epoch 159/1000\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.4604 - accuracy: 0.8410 - val_loss: 0.4727 - val_accuracy: 0.8525 - lr: 8.0000e-04\n",
      "Epoch 160/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.4626 - accuracy: 0.8295 - val_loss: 0.4857 - val_accuracy: 0.8561 - lr: 8.0000e-04\n",
      "Epoch 161/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4810 - accuracy: 0.8314 - val_loss: 0.4891 - val_accuracy: 0.8525 - lr: 8.0000e-04\n",
      "Epoch 162/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4571 - accuracy: 0.8340 - val_loss: 0.5590 - val_accuracy: 0.8381 - lr: 8.0000e-04\n",
      "Epoch 163/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.4572 - accuracy: 0.8276 - val_loss: 0.5068 - val_accuracy: 0.8561 - lr: 8.0000e-04\n",
      "Epoch 164/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.4747 - accuracy: 0.8263 - val_loss: 0.4984 - val_accuracy: 0.8525 - lr: 8.0000e-04\n",
      "Epoch 165/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4827 - accuracy: 0.8181 - val_loss: 0.6073 - val_accuracy: 0.8058 - lr: 8.0000e-04\n",
      "Epoch 166/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.5203 - accuracy: 0.8181 - val_loss: 0.4997 - val_accuracy: 0.8453 - lr: 8.0000e-04\n",
      "Epoch 167/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4595 - accuracy: 0.8257 - val_loss: 0.4793 - val_accuracy: 0.8453 - lr: 8.0000e-04\n",
      "Epoch 168/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4330 - accuracy: 0.8410 - val_loss: 0.4460 - val_accuracy: 0.8597 - lr: 8.0000e-04\n",
      "Epoch 169/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4890 - accuracy: 0.8149 - val_loss: 0.4926 - val_accuracy: 0.8489 - lr: 8.0000e-04\n",
      "Epoch 170/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4530 - accuracy: 0.8359 - val_loss: 0.5165 - val_accuracy: 0.8597 - lr: 8.0000e-04\n",
      "Epoch 171/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.5045 - accuracy: 0.8181 - val_loss: 0.4922 - val_accuracy: 0.8453 - lr: 8.0000e-04\n",
      "Epoch 172/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4544 - accuracy: 0.8359 - val_loss: 0.4817 - val_accuracy: 0.8309 - lr: 8.0000e-04\n",
      "Epoch 173/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4600 - accuracy: 0.8499 - val_loss: 0.5002 - val_accuracy: 0.8525 - lr: 8.0000e-04\n",
      "Epoch 174/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4211 - accuracy: 0.8543 - val_loss: 0.4921 - val_accuracy: 0.8237 - lr: 8.0000e-04\n",
      "Epoch 175/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4978 - accuracy: 0.8212 - val_loss: 0.5314 - val_accuracy: 0.8237 - lr: 8.0000e-04\n",
      "Epoch 176/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4848 - accuracy: 0.8257 - val_loss: 0.6007 - val_accuracy: 0.7914 - lr: 8.0000e-04\n",
      "Epoch 177/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.4950 - accuracy: 0.8321 - val_loss: 0.4484 - val_accuracy: 0.8741 - lr: 8.0000e-04\n",
      "Epoch 178/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.4163 - accuracy: 0.8524 - val_loss: 0.4390 - val_accuracy: 0.8741 - lr: 8.0000e-04\n",
      "Epoch 179/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.4333 - accuracy: 0.8327 - val_loss: 0.4620 - val_accuracy: 0.8489 - lr: 8.0000e-04\n",
      "Epoch 180/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4413 - accuracy: 0.8518 - val_loss: 0.4715 - val_accuracy: 0.8705 - lr: 8.0000e-04\n",
      "Epoch 181/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4045 - accuracy: 0.8562 - val_loss: 0.4388 - val_accuracy: 0.8489 - lr: 8.0000e-04\n",
      "Epoch 182/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4089 - accuracy: 0.8569 - val_loss: 0.4253 - val_accuracy: 0.8453 - lr: 8.0000e-04\n",
      "Epoch 183/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4168 - accuracy: 0.8480 - val_loss: 0.4608 - val_accuracy: 0.8525 - lr: 8.0000e-04\n",
      "Epoch 184/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4279 - accuracy: 0.8461 - val_loss: 0.5963 - val_accuracy: 0.7914 - lr: 8.0000e-04\n",
      "Epoch 185/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.8249 - accuracy: 0.7144 - val_loss: 0.5532 - val_accuracy: 0.7986 - lr: 8.0000e-04\n",
      "Epoch 186/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4905 - accuracy: 0.8162 - val_loss: 0.5506 - val_accuracy: 0.8453 - lr: 8.0000e-04\n",
      "Epoch 187/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.4179 - accuracy: 0.8613 - val_loss: 0.4579 - val_accuracy: 0.8633 - lr: 8.0000e-04\n",
      "Epoch 188/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4401 - accuracy: 0.8416 - val_loss: 0.6938 - val_accuracy: 0.7590 - lr: 8.0000e-04\n",
      "Epoch 189/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.9551 - accuracy: 0.6667 - val_loss: 0.6078 - val_accuracy: 0.8022 - lr: 8.0000e-04\n",
      "Epoch 190/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.5427 - accuracy: 0.8123 - val_loss: 0.5172 - val_accuracy: 0.8309 - lr: 8.0000e-04\n",
      "Epoch 191/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4810 - accuracy: 0.8333 - val_loss: 0.5005 - val_accuracy: 0.8201 - lr: 8.0000e-04\n",
      "Epoch 192/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4674 - accuracy: 0.8365 - val_loss: 0.4510 - val_accuracy: 0.8561 - lr: 8.0000e-04\n",
      "Epoch 193/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4729 - accuracy: 0.8302 - val_loss: 0.4459 - val_accuracy: 0.8777 - lr: 6.4000e-04\n",
      "Epoch 194/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.4273 - accuracy: 0.8550 - val_loss: 0.4224 - val_accuracy: 0.8849 - lr: 6.4000e-04\n",
      "Epoch 195/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3782 - accuracy: 0.8760 - val_loss: 0.4224 - val_accuracy: 0.8813 - lr: 6.4000e-04\n",
      "Epoch 196/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.4642 - accuracy: 0.8492 - val_loss: 0.5144 - val_accuracy: 0.8345 - lr: 6.4000e-04\n",
      "Epoch 197/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.4481 - accuracy: 0.8321 - val_loss: 0.5095 - val_accuracy: 0.8705 - lr: 6.4000e-04\n",
      "Epoch 198/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4122 - accuracy: 0.8607 - val_loss: 0.4461 - val_accuracy: 0.8597 - lr: 6.4000e-04\n",
      "Epoch 199/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3766 - accuracy: 0.8620 - val_loss: 0.4351 - val_accuracy: 0.8885 - lr: 6.4000e-04\n",
      "Epoch 200/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3878 - accuracy: 0.8588 - val_loss: 0.4555 - val_accuracy: 0.8741 - lr: 6.4000e-04\n",
      "Epoch 201/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3769 - accuracy: 0.8734 - val_loss: 0.4096 - val_accuracy: 0.8957 - lr: 6.4000e-04\n",
      "Epoch 202/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3737 - accuracy: 0.8632 - val_loss: 0.4235 - val_accuracy: 0.8813 - lr: 6.4000e-04\n",
      "Epoch 203/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4443 - accuracy: 0.8422 - val_loss: 0.4455 - val_accuracy: 0.8777 - lr: 6.4000e-04\n",
      "Epoch 204/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.4214 - accuracy: 0.8416 - val_loss: 0.4320 - val_accuracy: 0.8633 - lr: 6.4000e-04\n",
      "Epoch 205/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.3815 - accuracy: 0.8658 - val_loss: 0.4016 - val_accuracy: 0.8633 - lr: 6.4000e-04\n",
      "Epoch 206/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3446 - accuracy: 0.8810 - val_loss: 0.4047 - val_accuracy: 0.8777 - lr: 6.4000e-04\n",
      "Epoch 207/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3609 - accuracy: 0.8664 - val_loss: 0.4444 - val_accuracy: 0.8705 - lr: 6.4000e-04\n",
      "Epoch 208/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.4035 - accuracy: 0.8556 - val_loss: 0.4186 - val_accuracy: 0.8813 - lr: 6.4000e-04\n",
      "Epoch 209/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.3389 - accuracy: 0.8798 - val_loss: 0.3968 - val_accuracy: 0.8669 - lr: 6.4000e-04\n",
      "Epoch 210/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3521 - accuracy: 0.8734 - val_loss: 0.4626 - val_accuracy: 0.8561 - lr: 6.4000e-04\n",
      "Epoch 211/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.4143 - accuracy: 0.8486 - val_loss: 0.4655 - val_accuracy: 0.8705 - lr: 6.4000e-04\n",
      "Epoch 212/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3878 - accuracy: 0.8651 - val_loss: 0.4442 - val_accuracy: 0.8489 - lr: 6.4000e-04\n",
      "Epoch 213/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.3527 - accuracy: 0.8766 - val_loss: 0.4267 - val_accuracy: 0.8849 - lr: 6.4000e-04\n",
      "Epoch 214/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3528 - accuracy: 0.8753 - val_loss: 0.4265 - val_accuracy: 0.8633 - lr: 6.4000e-04\n",
      "Epoch 215/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3875 - accuracy: 0.8645 - val_loss: 0.4592 - val_accuracy: 0.8705 - lr: 6.4000e-04\n",
      "Epoch 216/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3373 - accuracy: 0.8849 - val_loss: 0.4062 - val_accuracy: 0.8993 - lr: 6.4000e-04\n",
      "Epoch 217/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.3387 - accuracy: 0.8899 - val_loss: 0.3607 - val_accuracy: 0.9029 - lr: 6.4000e-04\n",
      "Epoch 218/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3764 - accuracy: 0.8607 - val_loss: 0.4533 - val_accuracy: 0.8525 - lr: 6.4000e-04\n",
      "Epoch 219/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3441 - accuracy: 0.8785 - val_loss: 0.3993 - val_accuracy: 0.8777 - lr: 6.4000e-04\n",
      "Epoch 220/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3692 - accuracy: 0.8645 - val_loss: 0.4931 - val_accuracy: 0.8633 - lr: 6.4000e-04\n",
      "Epoch 221/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.4694 - accuracy: 0.8238 - val_loss: 0.4332 - val_accuracy: 0.8345 - lr: 6.4000e-04\n",
      "Epoch 222/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3341 - accuracy: 0.8874 - val_loss: 0.3747 - val_accuracy: 0.8885 - lr: 6.4000e-04\n",
      "Epoch 223/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3368 - accuracy: 0.8823 - val_loss: 0.4244 - val_accuracy: 0.8921 - lr: 6.4000e-04\n",
      "Epoch 224/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3604 - accuracy: 0.8645 - val_loss: 0.4044 - val_accuracy: 0.8705 - lr: 6.4000e-04\n",
      "Epoch 225/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.3323 - accuracy: 0.8830 - val_loss: 0.4073 - val_accuracy: 0.8561 - lr: 6.4000e-04\n",
      "Epoch 226/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3264 - accuracy: 0.8823 - val_loss: 0.4270 - val_accuracy: 0.8741 - lr: 6.4000e-04\n",
      "Epoch 227/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3434 - accuracy: 0.8766 - val_loss: 0.4021 - val_accuracy: 0.8705 - lr: 6.4000e-04\n",
      "Epoch 228/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3792 - accuracy: 0.8588 - val_loss: 0.3656 - val_accuracy: 0.8957 - lr: 5.1200e-04\n",
      "Epoch 229/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.3094 - accuracy: 0.8925 - val_loss: 0.3744 - val_accuracy: 0.8957 - lr: 5.1200e-04\n",
      "Epoch 230/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3274 - accuracy: 0.8868 - val_loss: 0.3880 - val_accuracy: 0.9029 - lr: 5.1200e-04\n",
      "Epoch 231/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3098 - accuracy: 0.8906 - val_loss: 0.3643 - val_accuracy: 0.8957 - lr: 5.1200e-04\n",
      "Epoch 232/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2788 - accuracy: 0.9039 - val_loss: 0.3815 - val_accuracy: 0.8705 - lr: 5.1200e-04\n",
      "Epoch 233/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.3248 - accuracy: 0.8893 - val_loss: 0.3678 - val_accuracy: 0.8813 - lr: 5.1200e-04\n",
      "Epoch 234/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3299 - accuracy: 0.8830 - val_loss: 0.3795 - val_accuracy: 0.8921 - lr: 5.1200e-04\n",
      "Epoch 235/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.3074 - accuracy: 0.8969 - val_loss: 0.3473 - val_accuracy: 0.9101 - lr: 5.1200e-04\n",
      "Epoch 236/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2887 - accuracy: 0.8976 - val_loss: 0.3986 - val_accuracy: 0.8957 - lr: 5.1200e-04\n",
      "Epoch 237/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.2931 - accuracy: 0.8976 - val_loss: 0.3616 - val_accuracy: 0.8741 - lr: 5.1200e-04\n",
      "Epoch 238/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3059 - accuracy: 0.8798 - val_loss: 0.3931 - val_accuracy: 0.8813 - lr: 5.1200e-04\n",
      "Epoch 239/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2985 - accuracy: 0.8830 - val_loss: 0.3632 - val_accuracy: 0.8885 - lr: 5.1200e-04\n",
      "Epoch 240/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2965 - accuracy: 0.8989 - val_loss: 0.3569 - val_accuracy: 0.8885 - lr: 5.1200e-04\n",
      "Epoch 241/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.3206 - accuracy: 0.8880 - val_loss: 0.3680 - val_accuracy: 0.9065 - lr: 5.1200e-04\n",
      "Epoch 242/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2932 - accuracy: 0.8938 - val_loss: 0.3592 - val_accuracy: 0.9065 - lr: 5.1200e-04\n",
      "Epoch 243/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2868 - accuracy: 0.9020 - val_loss: 0.3981 - val_accuracy: 0.8633 - lr: 5.1200e-04\n",
      "Epoch 244/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3223 - accuracy: 0.8899 - val_loss: 0.3536 - val_accuracy: 0.8921 - lr: 5.1200e-04\n",
      "Epoch 245/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.2717 - accuracy: 0.9078 - val_loss: 0.3391 - val_accuracy: 0.9029 - lr: 5.1200e-04\n",
      "Epoch 246/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2842 - accuracy: 0.9027 - val_loss: 0.3574 - val_accuracy: 0.8957 - lr: 5.1200e-04\n",
      "Epoch 247/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3164 - accuracy: 0.8817 - val_loss: 0.3993 - val_accuracy: 0.8849 - lr: 5.1200e-04\n",
      "Epoch 248/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3063 - accuracy: 0.8836 - val_loss: 0.3566 - val_accuracy: 0.8849 - lr: 5.1200e-04\n",
      "Epoch 249/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2976 - accuracy: 0.8931 - val_loss: 0.7532 - val_accuracy: 0.7914 - lr: 5.1200e-04\n",
      "Epoch 250/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3884 - accuracy: 0.8715 - val_loss: 0.3820 - val_accuracy: 0.8921 - lr: 5.1200e-04\n",
      "Epoch 251/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.2958 - accuracy: 0.9001 - val_loss: 0.3550 - val_accuracy: 0.8957 - lr: 5.1200e-04\n",
      "Epoch 252/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.2579 - accuracy: 0.9097 - val_loss: 0.3474 - val_accuracy: 0.8957 - lr: 5.1200e-04\n",
      "Epoch 253/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2903 - accuracy: 0.8963 - val_loss: 0.3414 - val_accuracy: 0.8957 - lr: 5.1200e-04\n",
      "Epoch 254/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2705 - accuracy: 0.9027 - val_loss: 0.3298 - val_accuracy: 0.8993 - lr: 5.1200e-04\n",
      "Epoch 255/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.2731 - accuracy: 0.9078 - val_loss: 0.3636 - val_accuracy: 0.8813 - lr: 5.1200e-04\n",
      "Epoch 256/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.2844 - accuracy: 0.8995 - val_loss: 0.3809 - val_accuracy: 0.9029 - lr: 5.1200e-04\n",
      "Epoch 257/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3075 - accuracy: 0.8925 - val_loss: 0.4112 - val_accuracy: 0.8849 - lr: 5.1200e-04\n",
      "Epoch 258/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.3897 - accuracy: 0.8581 - val_loss: 0.3416 - val_accuracy: 0.8993 - lr: 5.1200e-04\n",
      "Epoch 259/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2746 - accuracy: 0.9008 - val_loss: 0.4138 - val_accuracy: 0.8885 - lr: 5.1200e-04\n",
      "Epoch 260/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.2689 - accuracy: 0.9090 - val_loss: 0.3546 - val_accuracy: 0.8993 - lr: 5.1200e-04\n",
      "Epoch 261/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2587 - accuracy: 0.9179 - val_loss: 0.3538 - val_accuracy: 0.9101 - lr: 5.1200e-04\n",
      "Epoch 262/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.2565 - accuracy: 0.9128 - val_loss: 0.3786 - val_accuracy: 0.8633 - lr: 5.1200e-04\n",
      "Epoch 263/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.3007 - accuracy: 0.8868 - val_loss: 0.4009 - val_accuracy: 0.8669 - lr: 5.1200e-04\n",
      "Epoch 264/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2649 - accuracy: 0.9097 - val_loss: 0.3513 - val_accuracy: 0.8993 - lr: 5.1200e-04\n",
      "Epoch 265/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.2446 - accuracy: 0.9148 - val_loss: 0.3311 - val_accuracy: 0.8957 - lr: 4.0960e-04\n",
      "Epoch 266/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2594 - accuracy: 0.9128 - val_loss: 0.3201 - val_accuracy: 0.8957 - lr: 4.0960e-04\n",
      "Epoch 267/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2631 - accuracy: 0.9135 - val_loss: 0.3351 - val_accuracy: 0.8993 - lr: 4.0960e-04\n",
      "Epoch 268/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.2656 - accuracy: 0.9103 - val_loss: 0.4138 - val_accuracy: 0.8849 - lr: 4.0960e-04\n",
      "Epoch 269/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.3577 - accuracy: 0.8753 - val_loss: 0.3366 - val_accuracy: 0.8993 - lr: 4.0960e-04\n",
      "Epoch 270/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.2711 - accuracy: 0.9001 - val_loss: 0.3425 - val_accuracy: 0.9101 - lr: 4.0960e-04\n",
      "Epoch 271/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.2622 - accuracy: 0.9103 - val_loss: 0.3489 - val_accuracy: 0.9065 - lr: 4.0960e-04\n",
      "Epoch 272/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2449 - accuracy: 0.9173 - val_loss: 0.3866 - val_accuracy: 0.8705 - lr: 4.0960e-04\n",
      "Epoch 273/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2238 - accuracy: 0.9249 - val_loss: 0.3337 - val_accuracy: 0.9029 - lr: 4.0960e-04\n",
      "Epoch 274/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2257 - accuracy: 0.9218 - val_loss: 0.3539 - val_accuracy: 0.9029 - lr: 4.0960e-04\n",
      "Epoch 275/1000\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2683 - accuracy: 0.8989 - val_loss: 0.3575 - val_accuracy: 0.9029 - lr: 4.0960e-04\n",
      "Epoch 276/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.2485 - accuracy: 0.9128 - val_loss: 0.3490 - val_accuracy: 0.9065 - lr: 4.0960e-04\n",
      "Epoch 277/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2408 - accuracy: 0.9160 - val_loss: 0.3444 - val_accuracy: 0.8921 - lr: 4.0960e-04\n",
      "Epoch 278/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2459 - accuracy: 0.9173 - val_loss: 0.3446 - val_accuracy: 0.9065 - lr: 4.0960e-04\n",
      "Epoch 279/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.2548 - accuracy: 0.9097 - val_loss: 0.3284 - val_accuracy: 0.9065 - lr: 4.0960e-04\n",
      "Epoch 280/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.2745 - accuracy: 0.9046 - val_loss: 0.3310 - val_accuracy: 0.8993 - lr: 4.0960e-04\n",
      "Epoch 281/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2589 - accuracy: 0.9109 - val_loss: 0.3397 - val_accuracy: 0.8993 - lr: 4.0960e-04\n",
      "Epoch 282/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2266 - accuracy: 0.9186 - val_loss: 0.3383 - val_accuracy: 0.8885 - lr: 4.0960e-04\n",
      "Epoch 283/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.2385 - accuracy: 0.9179 - val_loss: 0.3249 - val_accuracy: 0.9173 - lr: 4.0960e-04\n",
      "Epoch 284/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2531 - accuracy: 0.9148 - val_loss: 0.3670 - val_accuracy: 0.9029 - lr: 3.2768e-04\n",
      "Epoch 285/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.2330 - accuracy: 0.9205 - val_loss: 0.3291 - val_accuracy: 0.9029 - lr: 3.2768e-04\n",
      "Epoch 286/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2180 - accuracy: 0.9230 - val_loss: 0.3408 - val_accuracy: 0.9137 - lr: 3.2768e-04\n",
      "Epoch 287/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2253 - accuracy: 0.9275 - val_loss: 0.3368 - val_accuracy: 0.9029 - lr: 3.2768e-04\n",
      "Epoch 288/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2232 - accuracy: 0.9288 - val_loss: 0.3408 - val_accuracy: 0.9065 - lr: 3.2768e-04\n",
      "Epoch 289/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2578 - accuracy: 0.9116 - val_loss: 0.3170 - val_accuracy: 0.9029 - lr: 3.2768e-04\n",
      "Epoch 290/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2429 - accuracy: 0.9198 - val_loss: 0.3275 - val_accuracy: 0.9029 - lr: 3.2768e-04\n",
      "Epoch 291/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2358 - accuracy: 0.9192 - val_loss: 0.3289 - val_accuracy: 0.9137 - lr: 3.2768e-04\n",
      "Epoch 292/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2269 - accuracy: 0.9256 - val_loss: 0.3321 - val_accuracy: 0.9173 - lr: 3.2768e-04\n",
      "Epoch 293/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2309 - accuracy: 0.9198 - val_loss: 0.3625 - val_accuracy: 0.8813 - lr: 3.2768e-04\n",
      "Epoch 294/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2369 - accuracy: 0.9167 - val_loss: 0.3377 - val_accuracy: 0.9137 - lr: 3.2768e-04\n",
      "Epoch 295/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2335 - accuracy: 0.9141 - val_loss: 0.3752 - val_accuracy: 0.8849 - lr: 3.2768e-04\n",
      "Epoch 296/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2539 - accuracy: 0.9039 - val_loss: 0.3338 - val_accuracy: 0.9065 - lr: 3.2768e-04\n",
      "Epoch 297/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2327 - accuracy: 0.9160 - val_loss: 0.3339 - val_accuracy: 0.8993 - lr: 3.2768e-04\n",
      "Epoch 298/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2457 - accuracy: 0.9103 - val_loss: 0.3174 - val_accuracy: 0.9101 - lr: 3.2768e-04\n",
      "Epoch 299/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.2255 - accuracy: 0.9275 - val_loss: 0.3432 - val_accuracy: 0.9209 - lr: 3.2768e-04\n",
      "Epoch 300/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2051 - accuracy: 0.9243 - val_loss: 0.3611 - val_accuracy: 0.9029 - lr: 3.2768e-04\n",
      "Epoch 301/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2109 - accuracy: 0.9268 - val_loss: 0.3245 - val_accuracy: 0.9065 - lr: 3.2768e-04\n",
      "Epoch 302/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2210 - accuracy: 0.9198 - val_loss: 0.3317 - val_accuracy: 0.9029 - lr: 3.2768e-04\n",
      "Epoch 303/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2187 - accuracy: 0.9179 - val_loss: 0.3347 - val_accuracy: 0.9209 - lr: 2.6214e-04\n",
      "Epoch 304/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2196 - accuracy: 0.9307 - val_loss: 0.3208 - val_accuracy: 0.9137 - lr: 2.6214e-04\n",
      "Epoch 305/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2075 - accuracy: 0.9313 - val_loss: 0.3215 - val_accuracy: 0.9101 - lr: 2.6214e-04\n",
      "Epoch 306/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2130 - accuracy: 0.9205 - val_loss: 0.3016 - val_accuracy: 0.9173 - lr: 2.6214e-04\n",
      "Epoch 307/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1993 - accuracy: 0.9326 - val_loss: 0.3212 - val_accuracy: 0.8957 - lr: 2.6214e-04\n",
      "Epoch 308/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2250 - accuracy: 0.9218 - val_loss: 0.3143 - val_accuracy: 0.9101 - lr: 2.6214e-04\n",
      "Epoch 309/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2216 - accuracy: 0.9224 - val_loss: 0.3195 - val_accuracy: 0.9029 - lr: 2.6214e-04\n",
      "Epoch 310/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2262 - accuracy: 0.9281 - val_loss: 0.3206 - val_accuracy: 0.9173 - lr: 2.6214e-04\n",
      "Epoch 311/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2085 - accuracy: 0.9262 - val_loss: 0.3100 - val_accuracy: 0.9209 - lr: 2.6214e-04\n",
      "Epoch 312/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.2059 - accuracy: 0.9300 - val_loss: 0.3169 - val_accuracy: 0.9245 - lr: 2.6214e-04\n",
      "Epoch 313/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2373 - accuracy: 0.9179 - val_loss: 0.3132 - val_accuracy: 0.9137 - lr: 2.6214e-04\n",
      "Epoch 314/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2105 - accuracy: 0.9249 - val_loss: 0.3011 - val_accuracy: 0.9065 - lr: 2.6214e-04\n",
      "Epoch 315/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2153 - accuracy: 0.9281 - val_loss: 0.3281 - val_accuracy: 0.9029 - lr: 2.6214e-04\n",
      "Epoch 316/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2091 - accuracy: 0.9288 - val_loss: 0.3125 - val_accuracy: 0.9101 - lr: 2.6214e-04\n",
      "Epoch 317/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2170 - accuracy: 0.9275 - val_loss: 0.3209 - val_accuracy: 0.8885 - lr: 2.6214e-04\n",
      "Epoch 318/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2395 - accuracy: 0.9122 - val_loss: 0.3268 - val_accuracy: 0.9101 - lr: 2.6214e-04\n",
      "Epoch 319/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2080 - accuracy: 0.9294 - val_loss: 0.3248 - val_accuracy: 0.8921 - lr: 2.6214e-04\n",
      "Epoch 320/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2198 - accuracy: 0.9198 - val_loss: 0.3290 - val_accuracy: 0.9029 - lr: 2.6214e-04\n",
      "Epoch 321/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2314 - accuracy: 0.9224 - val_loss: 0.3267 - val_accuracy: 0.9137 - lr: 2.6214e-04\n",
      "Epoch 322/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2243 - accuracy: 0.9230 - val_loss: 0.3318 - val_accuracy: 0.9173 - lr: 2.6214e-04\n",
      "Epoch 323/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2040 - accuracy: 0.9319 - val_loss: 0.3096 - val_accuracy: 0.9101 - lr: 2.6214e-04\n",
      "Epoch 324/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2156 - accuracy: 0.9275 - val_loss: 0.3333 - val_accuracy: 0.9209 - lr: 2.6214e-04\n",
      "Epoch 325/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2540 - accuracy: 0.9090 - val_loss: 0.3210 - val_accuracy: 0.9029 - lr: 2.0972e-04\n",
      "Epoch 326/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1949 - accuracy: 0.9345 - val_loss: 0.3101 - val_accuracy: 0.9209 - lr: 2.0972e-04\n",
      "Epoch 327/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1996 - accuracy: 0.9326 - val_loss: 0.3067 - val_accuracy: 0.9137 - lr: 2.0972e-04\n",
      "Epoch 328/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.2149 - accuracy: 0.9243 - val_loss: 0.3089 - val_accuracy: 0.9281 - lr: 2.0972e-04\n",
      "Epoch 329/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1980 - accuracy: 0.9351 - val_loss: 0.3103 - val_accuracy: 0.9065 - lr: 2.0972e-04\n",
      "Epoch 330/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2025 - accuracy: 0.9313 - val_loss: 0.3228 - val_accuracy: 0.9173 - lr: 2.0972e-04\n",
      "Epoch 331/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1928 - accuracy: 0.9383 - val_loss: 0.3230 - val_accuracy: 0.9173 - lr: 2.0972e-04\n",
      "Epoch 332/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2044 - accuracy: 0.9358 - val_loss: 0.3090 - val_accuracy: 0.9137 - lr: 2.0972e-04\n",
      "Epoch 333/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2094 - accuracy: 0.9205 - val_loss: 0.3174 - val_accuracy: 0.9137 - lr: 2.0972e-04\n",
      "Epoch 334/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2023 - accuracy: 0.9237 - val_loss: 0.3209 - val_accuracy: 0.9101 - lr: 2.0972e-04\n",
      "Epoch 335/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1932 - accuracy: 0.9288 - val_loss: 0.3097 - val_accuracy: 0.9101 - lr: 2.0972e-04\n",
      "Epoch 336/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1923 - accuracy: 0.9300 - val_loss: 0.3261 - val_accuracy: 0.9101 - lr: 2.0972e-04\n",
      "Epoch 337/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1995 - accuracy: 0.9294 - val_loss: 0.3183 - val_accuracy: 0.9101 - lr: 2.0972e-04\n",
      "Epoch 338/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2190 - accuracy: 0.9224 - val_loss: 0.3498 - val_accuracy: 0.9137 - lr: 2.0972e-04\n",
      "Epoch 339/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2044 - accuracy: 0.9338 - val_loss: 0.3394 - val_accuracy: 0.9101 - lr: 2.0972e-04\n",
      "Epoch 340/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2054 - accuracy: 0.9275 - val_loss: 0.3087 - val_accuracy: 0.9209 - lr: 2.0972e-04\n",
      "Epoch 341/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1962 - accuracy: 0.9358 - val_loss: 0.3212 - val_accuracy: 0.9137 - lr: 2.0972e-04\n",
      "Epoch 342/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1963 - accuracy: 0.9338 - val_loss: 0.3225 - val_accuracy: 0.9173 - lr: 2.0972e-04\n",
      "Epoch 343/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1966 - accuracy: 0.9300 - val_loss: 0.3173 - val_accuracy: 0.9101 - lr: 2.0972e-04\n",
      "Epoch 344/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1983 - accuracy: 0.9351 - val_loss: 0.2936 - val_accuracy: 0.9173 - lr: 1.6777e-04\n",
      "Epoch 345/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1963 - accuracy: 0.9358 - val_loss: 0.3048 - val_accuracy: 0.9029 - lr: 1.6777e-04\n",
      "Epoch 346/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1874 - accuracy: 0.9389 - val_loss: 0.3043 - val_accuracy: 0.9173 - lr: 1.6777e-04\n",
      "Epoch 347/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1938 - accuracy: 0.9383 - val_loss: 0.2930 - val_accuracy: 0.9209 - lr: 1.6777e-04\n",
      "Epoch 348/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.2069 - accuracy: 0.9319 - val_loss: 0.3235 - val_accuracy: 0.8957 - lr: 1.6777e-04\n",
      "Epoch 349/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1946 - accuracy: 0.9345 - val_loss: 0.2963 - val_accuracy: 0.9173 - lr: 1.6777e-04\n",
      "Epoch 350/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1855 - accuracy: 0.9345 - val_loss: 0.3313 - val_accuracy: 0.9173 - lr: 1.6777e-04\n",
      "Epoch 351/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1863 - accuracy: 0.9345 - val_loss: 0.3036 - val_accuracy: 0.9209 - lr: 1.6777e-04\n",
      "Epoch 352/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1879 - accuracy: 0.9421 - val_loss: 0.3145 - val_accuracy: 0.9281 - lr: 1.6777e-04\n",
      "Epoch 353/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1822 - accuracy: 0.9459 - val_loss: 0.2951 - val_accuracy: 0.9173 - lr: 1.6777e-04\n",
      "Epoch 354/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1981 - accuracy: 0.9396 - val_loss: 0.2983 - val_accuracy: 0.9245 - lr: 1.6777e-04\n",
      "Epoch 355/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1942 - accuracy: 0.9345 - val_loss: 0.2955 - val_accuracy: 0.9173 - lr: 1.6777e-04\n",
      "Epoch 356/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1841 - accuracy: 0.9332 - val_loss: 0.2920 - val_accuracy: 0.9173 - lr: 1.6777e-04\n",
      "Epoch 357/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1824 - accuracy: 0.9427 - val_loss: 0.3039 - val_accuracy: 0.9137 - lr: 1.6777e-04\n",
      "Epoch 358/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1988 - accuracy: 0.9281 - val_loss: 0.2817 - val_accuracy: 0.9065 - lr: 1.6777e-04\n",
      "Epoch 359/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1953 - accuracy: 0.9300 - val_loss: 0.3133 - val_accuracy: 0.9209 - lr: 1.6777e-04\n",
      "Epoch 360/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1702 - accuracy: 0.9485 - val_loss: 0.3057 - val_accuracy: 0.9209 - lr: 1.6777e-04\n",
      "Epoch 361/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1754 - accuracy: 0.9421 - val_loss: 0.3047 - val_accuracy: 0.9209 - lr: 1.6777e-04\n",
      "Epoch 362/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1680 - accuracy: 0.9497 - val_loss: 0.3145 - val_accuracy: 0.9137 - lr: 1.6777e-04\n",
      "Epoch 363/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1815 - accuracy: 0.9396 - val_loss: 0.2937 - val_accuracy: 0.9137 - lr: 1.6777e-04\n",
      "Epoch 364/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1819 - accuracy: 0.9447 - val_loss: 0.3107 - val_accuracy: 0.9065 - lr: 1.6777e-04\n",
      "Epoch 365/1000\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.1756 - accuracy: 0.9389 - val_loss: 0.3002 - val_accuracy: 0.9209 - lr: 1.6777e-04\n",
      "Epoch 366/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1766 - accuracy: 0.9421 - val_loss: 0.3014 - val_accuracy: 0.9209 - lr: 1.6777e-04\n",
      "Epoch 367/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1691 - accuracy: 0.9459 - val_loss: 0.3208 - val_accuracy: 0.9101 - lr: 1.6777e-04\n",
      "Epoch 368/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1799 - accuracy: 0.9389 - val_loss: 0.3032 - val_accuracy: 0.9281 - lr: 1.6777e-04\n",
      "Epoch 369/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1801 - accuracy: 0.9358 - val_loss: 0.3037 - val_accuracy: 0.9209 - lr: 1.3422e-04\n",
      "Epoch 370/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1961 - accuracy: 0.9358 - val_loss: 0.3060 - val_accuracy: 0.9173 - lr: 1.3422e-04\n",
      "Epoch 371/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1877 - accuracy: 0.9389 - val_loss: 0.3093 - val_accuracy: 0.9137 - lr: 1.3422e-04\n",
      "Epoch 372/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1724 - accuracy: 0.9466 - val_loss: 0.3175 - val_accuracy: 0.9137 - lr: 1.3422e-04\n",
      "Epoch 373/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1828 - accuracy: 0.9351 - val_loss: 0.2946 - val_accuracy: 0.9317 - lr: 1.3422e-04\n",
      "Epoch 374/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1736 - accuracy: 0.9402 - val_loss: 0.2985 - val_accuracy: 0.9173 - lr: 1.3422e-04\n",
      "Epoch 375/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1867 - accuracy: 0.9364 - val_loss: 0.3226 - val_accuracy: 0.9173 - lr: 1.3422e-04\n",
      "Epoch 376/1000\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1868 - accuracy: 0.9377 - val_loss: 0.3038 - val_accuracy: 0.9137 - lr: 1.3422e-04\n",
      "Epoch 377/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1811 - accuracy: 0.9370 - val_loss: 0.3103 - val_accuracy: 0.9209 - lr: 1.3422e-04\n",
      "Epoch 378/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1760 - accuracy: 0.9389 - val_loss: 0.3055 - val_accuracy: 0.9245 - lr: 1.3422e-04\n",
      "Epoch 379/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1822 - accuracy: 0.9389 - val_loss: 0.3100 - val_accuracy: 0.9317 - lr: 1.3422e-04\n",
      "Epoch 380/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1766 - accuracy: 0.9402 - val_loss: 0.2984 - val_accuracy: 0.9209 - lr: 1.3422e-04\n",
      "Epoch 381/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1882 - accuracy: 0.9351 - val_loss: 0.3254 - val_accuracy: 0.9317 - lr: 1.3422e-04\n",
      "Epoch 382/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1744 - accuracy: 0.9478 - val_loss: 0.3041 - val_accuracy: 0.9209 - lr: 1.3422e-04\n",
      "Epoch 383/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1753 - accuracy: 0.9402 - val_loss: 0.2953 - val_accuracy: 0.9245 - lr: 1.3422e-04\n",
      "Epoch 384/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1964 - accuracy: 0.9415 - val_loss: 0.2921 - val_accuracy: 0.9173 - lr: 1.3422e-04\n",
      "Epoch 385/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.2048 - accuracy: 0.9300 - val_loss: 0.3038 - val_accuracy: 0.9209 - lr: 1.3422e-04\n",
      "Epoch 386/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1712 - accuracy: 0.9491 - val_loss: 0.3074 - val_accuracy: 0.9209 - lr: 1.3422e-04\n",
      "Epoch 387/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1709 - accuracy: 0.9447 - val_loss: 0.2991 - val_accuracy: 0.9245 - lr: 1.3422e-04\n",
      "Epoch 388/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1726 - accuracy: 0.9434 - val_loss: 0.2974 - val_accuracy: 0.9245 - lr: 1.0737e-04\n",
      "Epoch 389/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2002 - accuracy: 0.9307 - val_loss: 0.2859 - val_accuracy: 0.9245 - lr: 1.0737e-04\n",
      "Epoch 390/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2018 - accuracy: 0.9307 - val_loss: 0.2887 - val_accuracy: 0.9173 - lr: 1.0737e-04\n",
      "Epoch 391/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1692 - accuracy: 0.9440 - val_loss: 0.2788 - val_accuracy: 0.9281 - lr: 1.0737e-04\n",
      "Epoch 392/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1704 - accuracy: 0.9459 - val_loss: 0.2943 - val_accuracy: 0.9245 - lr: 1.0737e-04\n",
      "Epoch 393/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1653 - accuracy: 0.9427 - val_loss: 0.2904 - val_accuracy: 0.9209 - lr: 1.0737e-04\n",
      "Epoch 394/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1675 - accuracy: 0.9434 - val_loss: 0.2858 - val_accuracy: 0.9209 - lr: 1.0737e-04\n",
      "Epoch 395/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1886 - accuracy: 0.9370 - val_loss: 0.2907 - val_accuracy: 0.9281 - lr: 1.0737e-04\n",
      "Epoch 396/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1740 - accuracy: 0.9402 - val_loss: 0.2897 - val_accuracy: 0.9245 - lr: 1.0737e-04\n",
      "Epoch 397/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1639 - accuracy: 0.9466 - val_loss: 0.2974 - val_accuracy: 0.9209 - lr: 1.0737e-04\n",
      "Epoch 398/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1599 - accuracy: 0.9523 - val_loss: 0.3088 - val_accuracy: 0.9209 - lr: 1.0737e-04\n",
      "Epoch 399/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1591 - accuracy: 0.9485 - val_loss: 0.2953 - val_accuracy: 0.9245 - lr: 1.0737e-04\n",
      "Epoch 400/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1542 - accuracy: 0.9478 - val_loss: 0.2851 - val_accuracy: 0.9245 - lr: 1.0737e-04\n",
      "Epoch 401/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1669 - accuracy: 0.9478 - val_loss: 0.2911 - val_accuracy: 0.9209 - lr: 1.0737e-04\n",
      "Epoch 402/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1736 - accuracy: 0.9466 - val_loss: 0.2859 - val_accuracy: 0.9245 - lr: 1.0737e-04\n",
      "Epoch 403/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1642 - accuracy: 0.9434 - val_loss: 0.2905 - val_accuracy: 0.9281 - lr: 1.0737e-04\n",
      "Epoch 404/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1656 - accuracy: 0.9478 - val_loss: 0.2884 - val_accuracy: 0.9388 - lr: 1.0737e-04\n",
      "Epoch 405/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1610 - accuracy: 0.9434 - val_loss: 0.3066 - val_accuracy: 0.9245 - lr: 1.0737e-04\n",
      "Epoch 406/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1614 - accuracy: 0.9440 - val_loss: 0.2923 - val_accuracy: 0.9209 - lr: 1.0737e-04\n",
      "Epoch 407/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1503 - accuracy: 0.9504 - val_loss: 0.2827 - val_accuracy: 0.9245 - lr: 8.5899e-05\n",
      "Epoch 408/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1565 - accuracy: 0.9453 - val_loss: 0.2850 - val_accuracy: 0.9245 - lr: 8.5899e-05\n",
      "Epoch 409/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1495 - accuracy: 0.9561 - val_loss: 0.2877 - val_accuracy: 0.9245 - lr: 8.5899e-05\n",
      "Epoch 410/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1566 - accuracy: 0.9466 - val_loss: 0.2920 - val_accuracy: 0.9245 - lr: 8.5899e-05\n",
      "Epoch 411/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1669 - accuracy: 0.9453 - val_loss: 0.2933 - val_accuracy: 0.9281 - lr: 8.5899e-05\n",
      "Epoch 412/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1661 - accuracy: 0.9421 - val_loss: 0.2944 - val_accuracy: 0.9281 - lr: 8.5899e-05\n",
      "Epoch 413/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1696 - accuracy: 0.9421 - val_loss: 0.2855 - val_accuracy: 0.9245 - lr: 8.5899e-05\n",
      "Epoch 414/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1690 - accuracy: 0.9485 - val_loss: 0.2927 - val_accuracy: 0.9209 - lr: 8.5899e-05\n",
      "Epoch 415/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1629 - accuracy: 0.9472 - val_loss: 0.2841 - val_accuracy: 0.9281 - lr: 8.5899e-05\n",
      "Epoch 416/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1648 - accuracy: 0.9453 - val_loss: 0.2882 - val_accuracy: 0.9317 - lr: 8.5899e-05\n",
      "Epoch 417/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1664 - accuracy: 0.9415 - val_loss: 0.2882 - val_accuracy: 0.9245 - lr: 8.5899e-05\n",
      "Epoch 418/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1773 - accuracy: 0.9396 - val_loss: 0.2966 - val_accuracy: 0.9317 - lr: 8.5899e-05\n",
      "Epoch 419/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1711 - accuracy: 0.9421 - val_loss: 0.2857 - val_accuracy: 0.9245 - lr: 8.5899e-05\n",
      "Epoch 420/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1623 - accuracy: 0.9504 - val_loss: 0.2857 - val_accuracy: 0.9317 - lr: 8.5899e-05\n",
      "Epoch 421/1000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.1604 - accuracy: 0.9466 - val_loss: 0.2849 - val_accuracy: 0.9209 - lr: 8.5899e-05\n",
      "Epoch 422/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1547 - accuracy: 0.9555 - val_loss: 0.2913 - val_accuracy: 0.9281 - lr: 8.5899e-05\n",
      "Epoch 423/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1759 - accuracy: 0.9472 - val_loss: 0.3039 - val_accuracy: 0.9173 - lr: 8.5899e-05\n",
      "Epoch 424/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1638 - accuracy: 0.9478 - val_loss: 0.3076 - val_accuracy: 0.9281 - lr: 8.5899e-05\n",
      "Epoch 425/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1599 - accuracy: 0.9453 - val_loss: 0.2824 - val_accuracy: 0.9173 - lr: 8.5899e-05\n",
      "Epoch 426/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1693 - accuracy: 0.9510 - val_loss: 0.2871 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 427/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1735 - accuracy: 0.9427 - val_loss: 0.2903 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 428/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1588 - accuracy: 0.9472 - val_loss: 0.2910 - val_accuracy: 0.9281 - lr: 6.8719e-05\n",
      "Epoch 429/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1724 - accuracy: 0.9459 - val_loss: 0.2846 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 430/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1556 - accuracy: 0.9478 - val_loss: 0.2887 - val_accuracy: 0.9353 - lr: 6.8719e-05\n",
      "Epoch 431/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1604 - accuracy: 0.9517 - val_loss: 0.2918 - val_accuracy: 0.9317 - lr: 6.8719e-05\n",
      "Epoch 432/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1700 - accuracy: 0.9466 - val_loss: 0.2802 - val_accuracy: 0.9281 - lr: 6.8719e-05\n",
      "Epoch 433/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1615 - accuracy: 0.9447 - val_loss: 0.2920 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 434/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1518 - accuracy: 0.9491 - val_loss: 0.2861 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 435/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1723 - accuracy: 0.9427 - val_loss: 0.2959 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 436/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1688 - accuracy: 0.9434 - val_loss: 0.2948 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 437/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1667 - accuracy: 0.9440 - val_loss: 0.2929 - val_accuracy: 0.9317 - lr: 6.8719e-05\n",
      "Epoch 438/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1436 - accuracy: 0.9555 - val_loss: 0.2830 - val_accuracy: 0.9353 - lr: 6.8719e-05\n",
      "Epoch 439/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1595 - accuracy: 0.9485 - val_loss: 0.2779 - val_accuracy: 0.9317 - lr: 6.8719e-05\n",
      "Epoch 440/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1511 - accuracy: 0.9504 - val_loss: 0.2817 - val_accuracy: 0.9317 - lr: 6.8719e-05\n",
      "Epoch 441/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1558 - accuracy: 0.9485 - val_loss: 0.2866 - val_accuracy: 0.9317 - lr: 6.8719e-05\n",
      "Epoch 442/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1701 - accuracy: 0.9440 - val_loss: 0.2907 - val_accuracy: 0.9281 - lr: 6.8719e-05\n",
      "Epoch 443/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.1611 - accuracy: 0.9434 - val_loss: 0.2757 - val_accuracy: 0.9209 - lr: 6.8719e-05\n",
      "Epoch 444/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1690 - accuracy: 0.9434 - val_loss: 0.2792 - val_accuracy: 0.9317 - lr: 6.8719e-05\n",
      "Epoch 445/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1740 - accuracy: 0.9300 - val_loss: 0.2862 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 446/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1548 - accuracy: 0.9485 - val_loss: 0.2936 - val_accuracy: 0.9245 - lr: 6.8719e-05\n",
      "Epoch 447/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1647 - accuracy: 0.9491 - val_loss: 0.2848 - val_accuracy: 0.9209 - lr: 6.8719e-05\n",
      "Epoch 448/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1566 - accuracy: 0.9478 - val_loss: 0.2793 - val_accuracy: 0.9281 - lr: 6.8719e-05\n",
      "Epoch 449/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1616 - accuracy: 0.9491 - val_loss: 0.2929 - val_accuracy: 0.9173 - lr: 6.8719e-05\n",
      "Epoch 450/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1703 - accuracy: 0.9389 - val_loss: 0.2803 - val_accuracy: 0.9281 - lr: 6.8719e-05\n",
      "Epoch 451/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1725 - accuracy: 0.9434 - val_loss: 0.2811 - val_accuracy: 0.9317 - lr: 6.8719e-05\n",
      "Epoch 452/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1552 - accuracy: 0.9466 - val_loss: 0.2827 - val_accuracy: 0.9281 - lr: 6.8719e-05\n",
      "Epoch 453/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1536 - accuracy: 0.9504 - val_loss: 0.2808 - val_accuracy: 0.9209 - lr: 6.8719e-05\n",
      "Epoch 454/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1480 - accuracy: 0.9523 - val_loss: 0.2781 - val_accuracy: 0.9245 - lr: 5.4976e-05\n",
      "Epoch 455/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1534 - accuracy: 0.9542 - val_loss: 0.2875 - val_accuracy: 0.9281 - lr: 5.4976e-05\n",
      "Epoch 456/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1679 - accuracy: 0.9427 - val_loss: 0.2847 - val_accuracy: 0.9281 - lr: 5.4976e-05\n",
      "Epoch 457/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1405 - accuracy: 0.9529 - val_loss: 0.2904 - val_accuracy: 0.9281 - lr: 5.4976e-05\n",
      "Epoch 458/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1692 - accuracy: 0.9478 - val_loss: 0.2822 - val_accuracy: 0.9209 - lr: 5.4976e-05\n",
      "Epoch 459/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1558 - accuracy: 0.9415 - val_loss: 0.2813 - val_accuracy: 0.9245 - lr: 5.4976e-05\n",
      "Epoch 460/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1520 - accuracy: 0.9517 - val_loss: 0.2930 - val_accuracy: 0.9281 - lr: 5.4976e-05\n",
      "Epoch 461/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1522 - accuracy: 0.9510 - val_loss: 0.2871 - val_accuracy: 0.9388 - lr: 5.4976e-05\n",
      "Epoch 462/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1538 - accuracy: 0.9459 - val_loss: 0.2909 - val_accuracy: 0.9173 - lr: 5.4976e-05\n",
      "Epoch 463/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1484 - accuracy: 0.9504 - val_loss: 0.2849 - val_accuracy: 0.9245 - lr: 5.4976e-05\n",
      "Epoch 464/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1639 - accuracy: 0.9453 - val_loss: 0.2899 - val_accuracy: 0.9281 - lr: 5.4976e-05\n",
      "Epoch 465/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1610 - accuracy: 0.9478 - val_loss: 0.2962 - val_accuracy: 0.9209 - lr: 5.4976e-05\n",
      "Epoch 466/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1698 - accuracy: 0.9434 - val_loss: 0.2979 - val_accuracy: 0.9281 - lr: 5.4976e-05\n",
      "Epoch 467/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1606 - accuracy: 0.9510 - val_loss: 0.2860 - val_accuracy: 0.9209 - lr: 5.4976e-05\n",
      "Epoch 468/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1556 - accuracy: 0.9453 - val_loss: 0.2921 - val_accuracy: 0.9281 - lr: 5.4976e-05\n",
      "Epoch 469/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1639 - accuracy: 0.9485 - val_loss: 0.2963 - val_accuracy: 0.9245 - lr: 5.4976e-05\n",
      "Epoch 470/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1664 - accuracy: 0.9427 - val_loss: 0.2870 - val_accuracy: 0.9209 - lr: 5.4976e-05\n",
      "Epoch 471/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1657 - accuracy: 0.9427 - val_loss: 0.2876 - val_accuracy: 0.9209 - lr: 5.4976e-05\n",
      "Epoch 472/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1578 - accuracy: 0.9472 - val_loss: 0.2851 - val_accuracy: 0.9245 - lr: 5.4976e-05\n",
      "Epoch 473/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1678 - accuracy: 0.9427 - val_loss: 0.2801 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 474/1000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.1642 - accuracy: 0.9447 - val_loss: 0.2825 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 475/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1571 - accuracy: 0.9466 - val_loss: 0.2752 - val_accuracy: 0.9281 - lr: 4.3980e-05\n",
      "Epoch 476/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1533 - accuracy: 0.9440 - val_loss: 0.2860 - val_accuracy: 0.9317 - lr: 4.3980e-05\n",
      "Epoch 477/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1601 - accuracy: 0.9459 - val_loss: 0.2740 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 478/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1577 - accuracy: 0.9523 - val_loss: 0.2705 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 479/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1596 - accuracy: 0.9466 - val_loss: 0.2694 - val_accuracy: 0.9281 - lr: 4.3980e-05\n",
      "Epoch 480/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1488 - accuracy: 0.9542 - val_loss: 0.2653 - val_accuracy: 0.9317 - lr: 4.3980e-05\n",
      "Epoch 481/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1384 - accuracy: 0.9587 - val_loss: 0.2696 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 482/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1527 - accuracy: 0.9504 - val_loss: 0.2797 - val_accuracy: 0.9209 - lr: 4.3980e-05\n",
      "Epoch 483/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1510 - accuracy: 0.9472 - val_loss: 0.2676 - val_accuracy: 0.9281 - lr: 4.3980e-05\n",
      "Epoch 484/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1645 - accuracy: 0.9377 - val_loss: 0.2844 - val_accuracy: 0.9353 - lr: 4.3980e-05\n",
      "Epoch 485/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1577 - accuracy: 0.9497 - val_loss: 0.2750 - val_accuracy: 0.9281 - lr: 4.3980e-05\n",
      "Epoch 486/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1613 - accuracy: 0.9523 - val_loss: 0.2699 - val_accuracy: 0.9281 - lr: 4.3980e-05\n",
      "Epoch 487/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1464 - accuracy: 0.9510 - val_loss: 0.2753 - val_accuracy: 0.9353 - lr: 4.3980e-05\n",
      "Epoch 488/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1548 - accuracy: 0.9466 - val_loss: 0.2719 - val_accuracy: 0.9209 - lr: 4.3980e-05\n",
      "Epoch 489/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1610 - accuracy: 0.9447 - val_loss: 0.2600 - val_accuracy: 0.9317 - lr: 4.3980e-05\n",
      "Epoch 490/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1614 - accuracy: 0.9453 - val_loss: 0.2621 - val_accuracy: 0.9317 - lr: 4.3980e-05\n",
      "Epoch 491/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1435 - accuracy: 0.9523 - val_loss: 0.2681 - val_accuracy: 0.9317 - lr: 4.3980e-05\n",
      "Epoch 492/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1579 - accuracy: 0.9453 - val_loss: 0.2726 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 493/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1571 - accuracy: 0.9504 - val_loss: 0.2714 - val_accuracy: 0.9281 - lr: 4.3980e-05\n",
      "Epoch 494/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1538 - accuracy: 0.9510 - val_loss: 0.2662 - val_accuracy: 0.9317 - lr: 4.3980e-05\n",
      "Epoch 495/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1317 - accuracy: 0.9580 - val_loss: 0.2713 - val_accuracy: 0.9281 - lr: 4.3980e-05\n",
      "Epoch 496/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1609 - accuracy: 0.9440 - val_loss: 0.2677 - val_accuracy: 0.9317 - lr: 4.3980e-05\n",
      "Epoch 497/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1525 - accuracy: 0.9517 - val_loss: 0.2681 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 498/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1383 - accuracy: 0.9612 - val_loss: 0.2683 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 499/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1495 - accuracy: 0.9510 - val_loss: 0.2648 - val_accuracy: 0.9245 - lr: 4.3980e-05\n",
      "Epoch 500/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1590 - accuracy: 0.9453 - val_loss: 0.2684 - val_accuracy: 0.9245 - lr: 3.5184e-05\n",
      "Epoch 501/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1458 - accuracy: 0.9536 - val_loss: 0.2618 - val_accuracy: 0.9317 - lr: 3.5184e-05\n",
      "Epoch 502/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1621 - accuracy: 0.9440 - val_loss: 0.2684 - val_accuracy: 0.9245 - lr: 3.5184e-05\n",
      "Epoch 503/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1658 - accuracy: 0.9402 - val_loss: 0.2651 - val_accuracy: 0.9281 - lr: 3.5184e-05\n",
      "Epoch 504/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1392 - accuracy: 0.9606 - val_loss: 0.2617 - val_accuracy: 0.9317 - lr: 3.5184e-05\n",
      "Epoch 505/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1452 - accuracy: 0.9497 - val_loss: 0.2678 - val_accuracy: 0.9281 - lr: 3.5184e-05\n",
      "Epoch 506/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1741 - accuracy: 0.9427 - val_loss: 0.2707 - val_accuracy: 0.9281 - lr: 3.5184e-05\n",
      "Epoch 507/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1589 - accuracy: 0.9459 - val_loss: 0.2709 - val_accuracy: 0.9281 - lr: 3.5184e-05\n",
      "Epoch 508/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1587 - accuracy: 0.9497 - val_loss: 0.2649 - val_accuracy: 0.9245 - lr: 3.5184e-05\n",
      "Epoch 509/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1508 - accuracy: 0.9510 - val_loss: 0.2688 - val_accuracy: 0.9245 - lr: 3.5184e-05\n",
      "Epoch 510/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1363 - accuracy: 0.9567 - val_loss: 0.2741 - val_accuracy: 0.9245 - lr: 3.5184e-05\n",
      "Epoch 511/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1526 - accuracy: 0.9536 - val_loss: 0.2642 - val_accuracy: 0.9317 - lr: 3.5184e-05\n",
      "Epoch 512/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1585 - accuracy: 0.9485 - val_loss: 0.2610 - val_accuracy: 0.9245 - lr: 3.5184e-05\n",
      "Epoch 513/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1541 - accuracy: 0.9497 - val_loss: 0.2667 - val_accuracy: 0.9317 - lr: 3.5184e-05\n",
      "Epoch 514/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1451 - accuracy: 0.9574 - val_loss: 0.2688 - val_accuracy: 0.9281 - lr: 3.5184e-05\n",
      "Epoch 515/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1503 - accuracy: 0.9510 - val_loss: 0.2764 - val_accuracy: 0.9317 - lr: 3.5184e-05\n",
      "Epoch 516/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1526 - accuracy: 0.9459 - val_loss: 0.2709 - val_accuracy: 0.9281 - lr: 3.5184e-05\n",
      "Epoch 517/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1474 - accuracy: 0.9580 - val_loss: 0.2680 - val_accuracy: 0.9245 - lr: 3.5184e-05\n",
      "Epoch 518/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1520 - accuracy: 0.9542 - val_loss: 0.2821 - val_accuracy: 0.9281 - lr: 3.5184e-05\n",
      "Epoch 519/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1339 - accuracy: 0.9567 - val_loss: 0.2767 - val_accuracy: 0.9245 - lr: 2.8147e-05\n",
      "Epoch 520/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1415 - accuracy: 0.9523 - val_loss: 0.2812 - val_accuracy: 0.9245 - lr: 2.8147e-05\n",
      "Epoch 521/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1447 - accuracy: 0.9485 - val_loss: 0.2764 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 522/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1466 - accuracy: 0.9529 - val_loss: 0.2807 - val_accuracy: 0.9317 - lr: 2.8147e-05\n",
      "Epoch 523/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1571 - accuracy: 0.9453 - val_loss: 0.2769 - val_accuracy: 0.9317 - lr: 2.8147e-05\n",
      "Epoch 524/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1581 - accuracy: 0.9447 - val_loss: 0.2745 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 525/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1508 - accuracy: 0.9434 - val_loss: 0.2825 - val_accuracy: 0.9317 - lr: 2.8147e-05\n",
      "Epoch 526/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1406 - accuracy: 0.9593 - val_loss: 0.2788 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 527/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1543 - accuracy: 0.9485 - val_loss: 0.2774 - val_accuracy: 0.9317 - lr: 2.8147e-05\n",
      "Epoch 528/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1568 - accuracy: 0.9517 - val_loss: 0.2806 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 529/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1351 - accuracy: 0.9599 - val_loss: 0.2700 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 530/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1485 - accuracy: 0.9447 - val_loss: 0.2732 - val_accuracy: 0.9245 - lr: 2.8147e-05\n",
      "Epoch 531/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1356 - accuracy: 0.9587 - val_loss: 0.2850 - val_accuracy: 0.9353 - lr: 2.8147e-05\n",
      "Epoch 532/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1404 - accuracy: 0.9517 - val_loss: 0.2772 - val_accuracy: 0.9245 - lr: 2.8147e-05\n",
      "Epoch 533/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1502 - accuracy: 0.9510 - val_loss: 0.2751 - val_accuracy: 0.9317 - lr: 2.8147e-05\n",
      "Epoch 534/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1558 - accuracy: 0.9510 - val_loss: 0.2688 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 535/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1424 - accuracy: 0.9555 - val_loss: 0.2736 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 536/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1416 - accuracy: 0.9523 - val_loss: 0.2744 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 537/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1606 - accuracy: 0.9402 - val_loss: 0.2760 - val_accuracy: 0.9281 - lr: 2.8147e-05\n",
      "Epoch 538/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1505 - accuracy: 0.9440 - val_loss: 0.2789 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 539/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1400 - accuracy: 0.9555 - val_loss: 0.2740 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 540/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1414 - accuracy: 0.9523 - val_loss: 0.2742 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 541/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1471 - accuracy: 0.9491 - val_loss: 0.2751 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 542/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1344 - accuracy: 0.9599 - val_loss: 0.2679 - val_accuracy: 0.9245 - lr: 2.2518e-05\n",
      "Epoch 543/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1402 - accuracy: 0.9593 - val_loss: 0.2644 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 544/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1505 - accuracy: 0.9536 - val_loss: 0.2739 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 545/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1543 - accuracy: 0.9523 - val_loss: 0.2662 - val_accuracy: 0.9281 - lr: 2.2518e-05\n",
      "Epoch 546/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1629 - accuracy: 0.9485 - val_loss: 0.2640 - val_accuracy: 0.9281 - lr: 2.2518e-05\n",
      "Epoch 547/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1373 - accuracy: 0.9612 - val_loss: 0.2670 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 548/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1543 - accuracy: 0.9517 - val_loss: 0.2698 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 549/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1314 - accuracy: 0.9561 - val_loss: 0.2670 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 550/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1602 - accuracy: 0.9491 - val_loss: 0.2707 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 551/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1506 - accuracy: 0.9523 - val_loss: 0.2746 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 552/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1393 - accuracy: 0.9491 - val_loss: 0.2712 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 553/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1528 - accuracy: 0.9491 - val_loss: 0.2708 - val_accuracy: 0.9281 - lr: 2.2518e-05\n",
      "Epoch 554/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1362 - accuracy: 0.9567 - val_loss: 0.2715 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 555/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1541 - accuracy: 0.9459 - val_loss: 0.2688 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 556/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1453 - accuracy: 0.9497 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 2.2518e-05\n",
      "Epoch 557/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1449 - accuracy: 0.9517 - val_loss: 0.2698 - val_accuracy: 0.9281 - lr: 1.8014e-05\n",
      "Epoch 558/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1417 - accuracy: 0.9536 - val_loss: 0.2678 - val_accuracy: 0.9281 - lr: 1.8014e-05\n",
      "Epoch 559/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1373 - accuracy: 0.9561 - val_loss: 0.2685 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 560/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1396 - accuracy: 0.9542 - val_loss: 0.2674 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 561/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1643 - accuracy: 0.9351 - val_loss: 0.2639 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 562/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1670 - accuracy: 0.9396 - val_loss: 0.2753 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 563/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1546 - accuracy: 0.9485 - val_loss: 0.2741 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 564/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1463 - accuracy: 0.9587 - val_loss: 0.2751 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 565/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1402 - accuracy: 0.9536 - val_loss: 0.2731 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 566/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1625 - accuracy: 0.9421 - val_loss: 0.2712 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 567/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1344 - accuracy: 0.9593 - val_loss: 0.2696 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 568/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1407 - accuracy: 0.9536 - val_loss: 0.2691 - val_accuracy: 0.9281 - lr: 1.8014e-05\n",
      "Epoch 569/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1366 - accuracy: 0.9529 - val_loss: 0.2698 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 570/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1445 - accuracy: 0.9523 - val_loss: 0.2713 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 571/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1466 - accuracy: 0.9517 - val_loss: 0.2701 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 572/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1459 - accuracy: 0.9504 - val_loss: 0.2675 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 573/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1436 - accuracy: 0.9491 - val_loss: 0.2701 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 574/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1483 - accuracy: 0.9510 - val_loss: 0.2716 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 575/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1473 - accuracy: 0.9517 - val_loss: 0.2746 - val_accuracy: 0.9317 - lr: 1.8014e-05\n",
      "Epoch 576/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1445 - accuracy: 0.9536 - val_loss: 0.2749 - val_accuracy: 0.9281 - lr: 1.4412e-05\n",
      "Epoch 577/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1556 - accuracy: 0.9472 - val_loss: 0.2738 - val_accuracy: 0.9317 - lr: 1.4412e-05\n",
      "Epoch 578/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1492 - accuracy: 0.9491 - val_loss: 0.2731 - val_accuracy: 0.9317 - lr: 1.4412e-05\n",
      "Epoch 579/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1487 - accuracy: 0.9548 - val_loss: 0.2702 - val_accuracy: 0.9281 - lr: 1.4412e-05\n",
      "Epoch 580/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1409 - accuracy: 0.9561 - val_loss: 0.2701 - val_accuracy: 0.9281 - lr: 1.4412e-05\n",
      "Epoch 581/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1465 - accuracy: 0.9548 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 1.4412e-05\n",
      "Epoch 582/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1464 - accuracy: 0.9485 - val_loss: 0.2685 - val_accuracy: 0.9245 - lr: 1.4412e-05\n",
      "Epoch 583/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1447 - accuracy: 0.9561 - val_loss: 0.2702 - val_accuracy: 0.9353 - lr: 1.4412e-05\n",
      "Epoch 584/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1502 - accuracy: 0.9517 - val_loss: 0.2667 - val_accuracy: 0.9245 - lr: 1.4412e-05\n",
      "Epoch 585/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1391 - accuracy: 0.9536 - val_loss: 0.2647 - val_accuracy: 0.9245 - lr: 1.4412e-05\n",
      "Epoch 586/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1377 - accuracy: 0.9580 - val_loss: 0.2670 - val_accuracy: 0.9245 - lr: 1.4412e-05\n",
      "Epoch 587/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1477 - accuracy: 0.9529 - val_loss: 0.2682 - val_accuracy: 0.9281 - lr: 1.4412e-05\n",
      "Epoch 588/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1547 - accuracy: 0.9504 - val_loss: 0.2724 - val_accuracy: 0.9317 - lr: 1.4412e-05\n",
      "Epoch 589/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1514 - accuracy: 0.9459 - val_loss: 0.2741 - val_accuracy: 0.9281 - lr: 1.4412e-05\n",
      "Epoch 590/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1493 - accuracy: 0.9466 - val_loss: 0.2680 - val_accuracy: 0.9281 - lr: 1.4412e-05\n",
      "Epoch 591/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1497 - accuracy: 0.9542 - val_loss: 0.2671 - val_accuracy: 0.9281 - lr: 1.4412e-05\n",
      "Epoch 592/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1411 - accuracy: 0.9567 - val_loss: 0.2685 - val_accuracy: 0.9281 - lr: 1.4412e-05\n",
      "Epoch 593/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1401 - accuracy: 0.9587 - val_loss: 0.2681 - val_accuracy: 0.9245 - lr: 1.4412e-05\n",
      "Epoch 594/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1504 - accuracy: 0.9517 - val_loss: 0.2754 - val_accuracy: 0.9245 - lr: 1.4412e-05\n",
      "Epoch 595/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1331 - accuracy: 0.9593 - val_loss: 0.2711 - val_accuracy: 0.9317 - lr: 1.1529e-05\n",
      "Epoch 596/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1331 - accuracy: 0.9517 - val_loss: 0.2703 - val_accuracy: 0.9317 - lr: 1.1529e-05\n",
      "Epoch 597/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1621 - accuracy: 0.9408 - val_loss: 0.2682 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 598/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1467 - accuracy: 0.9542 - val_loss: 0.2722 - val_accuracy: 0.9317 - lr: 1.1529e-05\n",
      "Epoch 599/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1511 - accuracy: 0.9510 - val_loss: 0.2678 - val_accuracy: 0.9245 - lr: 1.1529e-05\n",
      "Epoch 600/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1454 - accuracy: 0.9485 - val_loss: 0.2698 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 601/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1568 - accuracy: 0.9440 - val_loss: 0.2696 - val_accuracy: 0.9317 - lr: 1.1529e-05\n",
      "Epoch 602/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1401 - accuracy: 0.9612 - val_loss: 0.2689 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 603/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1392 - accuracy: 0.9523 - val_loss: 0.2711 - val_accuracy: 0.9245 - lr: 1.1529e-05\n",
      "Epoch 604/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1524 - accuracy: 0.9447 - val_loss: 0.2715 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 605/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1363 - accuracy: 0.9555 - val_loss: 0.2705 - val_accuracy: 0.9245 - lr: 1.1529e-05\n",
      "Epoch 606/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1406 - accuracy: 0.9510 - val_loss: 0.2659 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 607/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1532 - accuracy: 0.9447 - val_loss: 0.2672 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 608/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1424 - accuracy: 0.9491 - val_loss: 0.2700 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 609/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1466 - accuracy: 0.9555 - val_loss: 0.2724 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 610/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1462 - accuracy: 0.9523 - val_loss: 0.2713 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 611/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1424 - accuracy: 0.9523 - val_loss: 0.2686 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 612/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1410 - accuracy: 0.9536 - val_loss: 0.2660 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 613/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1338 - accuracy: 0.9618 - val_loss: 0.2665 - val_accuracy: 0.9281 - lr: 1.1529e-05\n",
      "Epoch 614/1000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.1569 - accuracy: 0.9447 - val_loss: 0.2682 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 615/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1430 - accuracy: 0.9561 - val_loss: 0.2667 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 616/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1417 - accuracy: 0.9510 - val_loss: 0.2665 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 617/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1444 - accuracy: 0.9491 - val_loss: 0.2703 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 618/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1470 - accuracy: 0.9523 - val_loss: 0.2726 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 619/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1493 - accuracy: 0.9548 - val_loss: 0.2738 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 620/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1310 - accuracy: 0.9644 - val_loss: 0.2683 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 621/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1501 - accuracy: 0.9523 - val_loss: 0.2695 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 622/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1403 - accuracy: 0.9555 - val_loss: 0.2721 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 623/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1303 - accuracy: 0.9593 - val_loss: 0.2676 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 624/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1442 - accuracy: 0.9567 - val_loss: 0.2684 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 625/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1255 - accuracy: 0.9618 - val_loss: 0.2681 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 626/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1487 - accuracy: 0.9478 - val_loss: 0.2673 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 627/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1430 - accuracy: 0.9536 - val_loss: 0.2687 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 628/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1355 - accuracy: 0.9536 - val_loss: 0.2660 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 629/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1490 - accuracy: 0.9485 - val_loss: 0.2643 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 630/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1371 - accuracy: 0.9536 - val_loss: 0.2670 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 631/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1532 - accuracy: 0.9447 - val_loss: 0.2684 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 632/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1403 - accuracy: 0.9593 - val_loss: 0.2710 - val_accuracy: 0.9353 - lr: 1.0000e-05\n",
      "Epoch 633/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1422 - accuracy: 0.9555 - val_loss: 0.2699 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 634/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1500 - accuracy: 0.9510 - val_loss: 0.2696 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 635/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1570 - accuracy: 0.9497 - val_loss: 0.2687 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 636/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1639 - accuracy: 0.9453 - val_loss: 0.2682 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 637/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1332 - accuracy: 0.9618 - val_loss: 0.2701 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 638/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1488 - accuracy: 0.9542 - val_loss: 0.2684 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 639/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1372 - accuracy: 0.9555 - val_loss: 0.2735 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 640/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1401 - accuracy: 0.9561 - val_loss: 0.2772 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 641/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1484 - accuracy: 0.9548 - val_loss: 0.2746 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 642/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1429 - accuracy: 0.9555 - val_loss: 0.2713 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 643/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1408 - accuracy: 0.9536 - val_loss: 0.2728 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 644/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1398 - accuracy: 0.9497 - val_loss: 0.2686 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 645/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1362 - accuracy: 0.9561 - val_loss: 0.2692 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 646/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1449 - accuracy: 0.9555 - val_loss: 0.2663 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 647/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1455 - accuracy: 0.9466 - val_loss: 0.2661 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 648/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1458 - accuracy: 0.9555 - val_loss: 0.2685 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 649/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1570 - accuracy: 0.9517 - val_loss: 0.2726 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 650/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1419 - accuracy: 0.9491 - val_loss: 0.2734 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 651/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1478 - accuracy: 0.9466 - val_loss: 0.2721 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 652/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1461 - accuracy: 0.9542 - val_loss: 0.2720 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 653/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1546 - accuracy: 0.9478 - val_loss: 0.2718 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 654/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1593 - accuracy: 0.9453 - val_loss: 0.2734 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 655/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1318 - accuracy: 0.9644 - val_loss: 0.2719 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 656/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1427 - accuracy: 0.9517 - val_loss: 0.2716 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 657/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1460 - accuracy: 0.9510 - val_loss: 0.2741 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 658/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1282 - accuracy: 0.9561 - val_loss: 0.2703 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 659/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1364 - accuracy: 0.9491 - val_loss: 0.2707 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 660/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1284 - accuracy: 0.9618 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 661/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1317 - accuracy: 0.9606 - val_loss: 0.2676 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 662/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1595 - accuracy: 0.9466 - val_loss: 0.2655 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 663/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1439 - accuracy: 0.9574 - val_loss: 0.2669 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 664/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1489 - accuracy: 0.9510 - val_loss: 0.2693 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 665/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1528 - accuracy: 0.9536 - val_loss: 0.2689 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 666/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1534 - accuracy: 0.9478 - val_loss: 0.2699 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 667/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1540 - accuracy: 0.9478 - val_loss: 0.2683 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 668/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1508 - accuracy: 0.9453 - val_loss: 0.2685 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 669/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1306 - accuracy: 0.9548 - val_loss: 0.2672 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 670/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1393 - accuracy: 0.9523 - val_loss: 0.2695 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 671/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1522 - accuracy: 0.9529 - val_loss: 0.2720 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 672/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1322 - accuracy: 0.9612 - val_loss: 0.2754 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 673/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1649 - accuracy: 0.9383 - val_loss: 0.2732 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 674/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1430 - accuracy: 0.9567 - val_loss: 0.2707 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 675/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1341 - accuracy: 0.9517 - val_loss: 0.2717 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 676/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1378 - accuracy: 0.9548 - val_loss: 0.2691 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 677/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1496 - accuracy: 0.9472 - val_loss: 0.2708 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 678/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1456 - accuracy: 0.9523 - val_loss: 0.2699 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 679/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1461 - accuracy: 0.9542 - val_loss: 0.2694 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 680/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1477 - accuracy: 0.9523 - val_loss: 0.2693 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 681/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1560 - accuracy: 0.9447 - val_loss: 0.2665 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 682/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1391 - accuracy: 0.9599 - val_loss: 0.2713 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 683/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1393 - accuracy: 0.9593 - val_loss: 0.2701 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 684/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1493 - accuracy: 0.9523 - val_loss: 0.2700 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 685/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1468 - accuracy: 0.9491 - val_loss: 0.2684 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 686/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1374 - accuracy: 0.9567 - val_loss: 0.2701 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 687/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1460 - accuracy: 0.9523 - val_loss: 0.2714 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 688/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1368 - accuracy: 0.9587 - val_loss: 0.2705 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 689/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1583 - accuracy: 0.9434 - val_loss: 0.2716 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 690/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1436 - accuracy: 0.9548 - val_loss: 0.2721 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 691/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1448 - accuracy: 0.9542 - val_loss: 0.2743 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 692/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1245 - accuracy: 0.9644 - val_loss: 0.2727 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 693/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1404 - accuracy: 0.9517 - val_loss: 0.2699 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 694/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1557 - accuracy: 0.9504 - val_loss: 0.2723 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 695/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1346 - accuracy: 0.9580 - val_loss: 0.2714 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 696/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1394 - accuracy: 0.9580 - val_loss: 0.2685 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 697/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1380 - accuracy: 0.9599 - val_loss: 0.2674 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 698/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1466 - accuracy: 0.9561 - val_loss: 0.2665 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 699/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1517 - accuracy: 0.9447 - val_loss: 0.2662 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 700/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1391 - accuracy: 0.9574 - val_loss: 0.2680 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 701/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1464 - accuracy: 0.9504 - val_loss: 0.2693 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 702/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1463 - accuracy: 0.9497 - val_loss: 0.2662 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 703/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1319 - accuracy: 0.9574 - val_loss: 0.2666 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 704/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1393 - accuracy: 0.9555 - val_loss: 0.2692 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 705/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1436 - accuracy: 0.9523 - val_loss: 0.2666 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 706/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1404 - accuracy: 0.9536 - val_loss: 0.2660 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 707/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1488 - accuracy: 0.9517 - val_loss: 0.2686 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 708/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1386 - accuracy: 0.9599 - val_loss: 0.2679 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 709/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1319 - accuracy: 0.9561 - val_loss: 0.2676 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 710/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1453 - accuracy: 0.9523 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 711/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1428 - accuracy: 0.9510 - val_loss: 0.2686 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 712/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1475 - accuracy: 0.9574 - val_loss: 0.2709 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 713/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1372 - accuracy: 0.9612 - val_loss: 0.2704 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 714/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1319 - accuracy: 0.9574 - val_loss: 0.2708 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 715/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1378 - accuracy: 0.9548 - val_loss: 0.2710 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 716/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1439 - accuracy: 0.9523 - val_loss: 0.2694 - val_accuracy: 0.9245 - lr: 1.0000e-05\n",
      "Epoch 717/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1716 - accuracy: 0.9421 - val_loss: 0.2666 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 718/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1374 - accuracy: 0.9548 - val_loss: 0.2688 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 719/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1315 - accuracy: 0.9587 - val_loss: 0.2696 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 720/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1434 - accuracy: 0.9567 - val_loss: 0.2682 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 721/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1327 - accuracy: 0.9587 - val_loss: 0.2690 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 722/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1356 - accuracy: 0.9555 - val_loss: 0.2696 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 723/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1342 - accuracy: 0.9567 - val_loss: 0.2700 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 724/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1486 - accuracy: 0.9466 - val_loss: 0.2694 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 725/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1367 - accuracy: 0.9580 - val_loss: 0.2726 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 726/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1451 - accuracy: 0.9529 - val_loss: 0.2710 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 727/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1455 - accuracy: 0.9542 - val_loss: 0.2736 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 728/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1328 - accuracy: 0.9548 - val_loss: 0.2724 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 729/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1479 - accuracy: 0.9478 - val_loss: 0.2740 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 730/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1564 - accuracy: 0.9453 - val_loss: 0.2712 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 731/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1388 - accuracy: 0.9656 - val_loss: 0.2730 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 732/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1413 - accuracy: 0.9523 - val_loss: 0.2754 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 733/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1428 - accuracy: 0.9478 - val_loss: 0.2762 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 734/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1418 - accuracy: 0.9548 - val_loss: 0.2759 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 735/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1347 - accuracy: 0.9567 - val_loss: 0.2715 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 736/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1446 - accuracy: 0.9517 - val_loss: 0.2695 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 737/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1486 - accuracy: 0.9491 - val_loss: 0.2736 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 738/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1343 - accuracy: 0.9606 - val_loss: 0.2705 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 739/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1361 - accuracy: 0.9580 - val_loss: 0.2742 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 740/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1499 - accuracy: 0.9497 - val_loss: 0.2780 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 741/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1545 - accuracy: 0.9536 - val_loss: 0.2745 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 742/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1525 - accuracy: 0.9542 - val_loss: 0.2764 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 743/1000\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.1328 - accuracy: 0.9529 - val_loss: 0.2765 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 744/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1272 - accuracy: 0.9618 - val_loss: 0.2780 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 745/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1527 - accuracy: 0.9517 - val_loss: 0.2765 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 746/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1476 - accuracy: 0.9472 - val_loss: 0.2789 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 747/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1305 - accuracy: 0.9580 - val_loss: 0.2749 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 748/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1447 - accuracy: 0.9542 - val_loss: 0.2734 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 749/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1364 - accuracy: 0.9587 - val_loss: 0.2740 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 750/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1276 - accuracy: 0.9555 - val_loss: 0.2740 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 751/1000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.1307 - accuracy: 0.9618 - val_loss: 0.2731 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 752/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1568 - accuracy: 0.9491 - val_loss: 0.2721 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 753/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1477 - accuracy: 0.9517 - val_loss: 0.2751 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 754/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1375 - accuracy: 0.9567 - val_loss: 0.2745 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 755/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1537 - accuracy: 0.9466 - val_loss: 0.2735 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 756/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1275 - accuracy: 0.9618 - val_loss: 0.2746 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 757/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1462 - accuracy: 0.9466 - val_loss: 0.2772 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 758/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1259 - accuracy: 0.9574 - val_loss: 0.2723 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 759/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1448 - accuracy: 0.9542 - val_loss: 0.2712 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 760/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1492 - accuracy: 0.9504 - val_loss: 0.2757 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 761/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1399 - accuracy: 0.9555 - val_loss: 0.2786 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 762/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1288 - accuracy: 0.9561 - val_loss: 0.2783 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 763/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1426 - accuracy: 0.9536 - val_loss: 0.2766 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 764/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1484 - accuracy: 0.9478 - val_loss: 0.2737 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 765/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1436 - accuracy: 0.9555 - val_loss: 0.2719 - val_accuracy: 0.9353 - lr: 1.0000e-05\n",
      "Epoch 766/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1409 - accuracy: 0.9529 - val_loss: 0.2712 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 767/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1406 - accuracy: 0.9510 - val_loss: 0.2731 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 768/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.1557 - accuracy: 0.9497 - val_loss: 0.2736 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 769/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1482 - accuracy: 0.9536 - val_loss: 0.2743 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 770/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1375 - accuracy: 0.9567 - val_loss: 0.2728 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 771/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1352 - accuracy: 0.9567 - val_loss: 0.2766 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 772/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1548 - accuracy: 0.9415 - val_loss: 0.2752 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 773/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1450 - accuracy: 0.9580 - val_loss: 0.2712 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 774/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1364 - accuracy: 0.9580 - val_loss: 0.2701 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 775/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1398 - accuracy: 0.9536 - val_loss: 0.2698 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 776/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1299 - accuracy: 0.9561 - val_loss: 0.2706 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 777/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1423 - accuracy: 0.9517 - val_loss: 0.2709 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 778/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1360 - accuracy: 0.9606 - val_loss: 0.2706 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 779/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1497 - accuracy: 0.9548 - val_loss: 0.2673 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 780/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1504 - accuracy: 0.9478 - val_loss: 0.2714 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 781/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1421 - accuracy: 0.9504 - val_loss: 0.2707 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 782/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1336 - accuracy: 0.9606 - val_loss: 0.2726 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 783/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1303 - accuracy: 0.9650 - val_loss: 0.2793 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 784/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1493 - accuracy: 0.9523 - val_loss: 0.2716 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 785/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1354 - accuracy: 0.9587 - val_loss: 0.2711 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 786/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1268 - accuracy: 0.9574 - val_loss: 0.2745 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 787/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1513 - accuracy: 0.9497 - val_loss: 0.2734 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 788/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1353 - accuracy: 0.9542 - val_loss: 0.2713 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 789/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1470 - accuracy: 0.9529 - val_loss: 0.2699 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 790/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1456 - accuracy: 0.9466 - val_loss: 0.2726 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 791/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1358 - accuracy: 0.9542 - val_loss: 0.2686 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 792/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1270 - accuracy: 0.9618 - val_loss: 0.2676 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 793/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1604 - accuracy: 0.9491 - val_loss: 0.2678 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 794/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1431 - accuracy: 0.9491 - val_loss: 0.2680 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 795/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1421 - accuracy: 0.9567 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 796/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1375 - accuracy: 0.9548 - val_loss: 0.2684 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 797/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1350 - accuracy: 0.9593 - val_loss: 0.2737 - val_accuracy: 0.9353 - lr: 1.0000e-05\n",
      "Epoch 798/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1440 - accuracy: 0.9542 - val_loss: 0.2733 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 799/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1398 - accuracy: 0.9593 - val_loss: 0.2736 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 800/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1461 - accuracy: 0.9517 - val_loss: 0.2737 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 801/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1367 - accuracy: 0.9504 - val_loss: 0.2660 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 802/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1360 - accuracy: 0.9548 - val_loss: 0.2677 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 803/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1443 - accuracy: 0.9517 - val_loss: 0.2705 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 804/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1407 - accuracy: 0.9536 - val_loss: 0.2684 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 805/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1544 - accuracy: 0.9466 - val_loss: 0.2694 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 806/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1443 - accuracy: 0.9542 - val_loss: 0.2691 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 807/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1497 - accuracy: 0.9497 - val_loss: 0.2728 - val_accuracy: 0.9353 - lr: 1.0000e-05\n",
      "Epoch 808/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1308 - accuracy: 0.9637 - val_loss: 0.2664 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 809/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1363 - accuracy: 0.9555 - val_loss: 0.2702 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 810/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1376 - accuracy: 0.9580 - val_loss: 0.2705 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 811/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1579 - accuracy: 0.9383 - val_loss: 0.2710 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 812/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1404 - accuracy: 0.9542 - val_loss: 0.2691 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 813/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1539 - accuracy: 0.9517 - val_loss: 0.2673 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 814/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1372 - accuracy: 0.9529 - val_loss: 0.2665 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 815/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1397 - accuracy: 0.9548 - val_loss: 0.2653 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 816/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1363 - accuracy: 0.9587 - val_loss: 0.2687 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 817/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1391 - accuracy: 0.9523 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 818/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1478 - accuracy: 0.9523 - val_loss: 0.2694 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 819/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1321 - accuracy: 0.9548 - val_loss: 0.2698 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 820/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1452 - accuracy: 0.9517 - val_loss: 0.2709 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 821/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1467 - accuracy: 0.9536 - val_loss: 0.2691 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 822/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1384 - accuracy: 0.9517 - val_loss: 0.2688 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 823/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1458 - accuracy: 0.9555 - val_loss: 0.2724 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 824/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1299 - accuracy: 0.9612 - val_loss: 0.2679 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 825/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1371 - accuracy: 0.9587 - val_loss: 0.2666 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 826/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1330 - accuracy: 0.9625 - val_loss: 0.2690 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 827/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1395 - accuracy: 0.9542 - val_loss: 0.2703 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 828/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1364 - accuracy: 0.9555 - val_loss: 0.2700 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 829/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1415 - accuracy: 0.9491 - val_loss: 0.2687 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 830/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1418 - accuracy: 0.9536 - val_loss: 0.2696 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 831/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1358 - accuracy: 0.9606 - val_loss: 0.2714 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 832/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1342 - accuracy: 0.9631 - val_loss: 0.2728 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 833/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1448 - accuracy: 0.9555 - val_loss: 0.2703 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 834/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1508 - accuracy: 0.9497 - val_loss: 0.2681 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 835/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1341 - accuracy: 0.9517 - val_loss: 0.2721 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 836/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1343 - accuracy: 0.9618 - val_loss: 0.2748 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 837/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1360 - accuracy: 0.9593 - val_loss: 0.2716 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 838/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1516 - accuracy: 0.9548 - val_loss: 0.2687 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 839/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.1253 - accuracy: 0.9587 - val_loss: 0.2662 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 840/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1461 - accuracy: 0.9478 - val_loss: 0.2688 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 841/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1450 - accuracy: 0.9561 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 842/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1428 - accuracy: 0.9459 - val_loss: 0.2733 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 843/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1373 - accuracy: 0.9574 - val_loss: 0.2716 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 844/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1350 - accuracy: 0.9587 - val_loss: 0.2734 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 845/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1371 - accuracy: 0.9561 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 846/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1411 - accuracy: 0.9548 - val_loss: 0.2698 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 847/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1365 - accuracy: 0.9523 - val_loss: 0.2682 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 848/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1334 - accuracy: 0.9593 - val_loss: 0.2693 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 849/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.1219 - accuracy: 0.9612 - val_loss: 0.2704 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 850/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1259 - accuracy: 0.9631 - val_loss: 0.2713 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 851/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1392 - accuracy: 0.9548 - val_loss: 0.2681 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 852/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1340 - accuracy: 0.9542 - val_loss: 0.2688 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 853/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1472 - accuracy: 0.9561 - val_loss: 0.2677 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 854/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1308 - accuracy: 0.9536 - val_loss: 0.2682 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 855/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1353 - accuracy: 0.9523 - val_loss: 0.2663 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 856/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1385 - accuracy: 0.9561 - val_loss: 0.2667 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 857/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1350 - accuracy: 0.9580 - val_loss: 0.2694 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 858/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1471 - accuracy: 0.9510 - val_loss: 0.2690 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 859/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1370 - accuracy: 0.9548 - val_loss: 0.2695 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 860/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1399 - accuracy: 0.9542 - val_loss: 0.2711 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 861/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1468 - accuracy: 0.9587 - val_loss: 0.2686 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 862/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1438 - accuracy: 0.9587 - val_loss: 0.2680 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 863/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1422 - accuracy: 0.9523 - val_loss: 0.2700 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 864/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1314 - accuracy: 0.9599 - val_loss: 0.2698 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 865/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1441 - accuracy: 0.9536 - val_loss: 0.2688 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 866/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1351 - accuracy: 0.9612 - val_loss: 0.2688 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 867/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1376 - accuracy: 0.9548 - val_loss: 0.2682 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 868/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1490 - accuracy: 0.9427 - val_loss: 0.2676 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 869/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1408 - accuracy: 0.9548 - val_loss: 0.2675 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 870/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1485 - accuracy: 0.9555 - val_loss: 0.2674 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 871/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1291 - accuracy: 0.9650 - val_loss: 0.2697 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 872/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1366 - accuracy: 0.9567 - val_loss: 0.2703 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 873/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1413 - accuracy: 0.9542 - val_loss: 0.2723 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 874/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1397 - accuracy: 0.9580 - val_loss: 0.2665 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 875/1000\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.1317 - accuracy: 0.9536 - val_loss: 0.2679 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 876/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1352 - accuracy: 0.9587 - val_loss: 0.2702 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 877/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1329 - accuracy: 0.9656 - val_loss: 0.2723 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 878/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1291 - accuracy: 0.9587 - val_loss: 0.2741 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 879/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1365 - accuracy: 0.9587 - val_loss: 0.2711 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 880/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1306 - accuracy: 0.9567 - val_loss: 0.2710 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 881/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1416 - accuracy: 0.9561 - val_loss: 0.2673 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 882/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1373 - accuracy: 0.9548 - val_loss: 0.2681 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 883/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1363 - accuracy: 0.9574 - val_loss: 0.2692 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 884/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1443 - accuracy: 0.9504 - val_loss: 0.2708 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 885/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1328 - accuracy: 0.9612 - val_loss: 0.2710 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 886/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1317 - accuracy: 0.9567 - val_loss: 0.2662 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 887/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1342 - accuracy: 0.9593 - val_loss: 0.2675 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 888/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1399 - accuracy: 0.9587 - val_loss: 0.2673 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 889/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1340 - accuracy: 0.9561 - val_loss: 0.2668 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 890/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.1411 - accuracy: 0.9599 - val_loss: 0.2662 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 891/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1314 - accuracy: 0.9574 - val_loss: 0.2667 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 892/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1363 - accuracy: 0.9580 - val_loss: 0.2660 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 893/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1439 - accuracy: 0.9510 - val_loss: 0.2678 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 894/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1439 - accuracy: 0.9523 - val_loss: 0.2662 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 895/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1307 - accuracy: 0.9606 - val_loss: 0.2636 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 896/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1382 - accuracy: 0.9593 - val_loss: 0.2679 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 897/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1365 - accuracy: 0.9599 - val_loss: 0.2652 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 898/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1287 - accuracy: 0.9618 - val_loss: 0.2662 - val_accuracy: 0.9353 - lr: 1.0000e-05\n",
      "Epoch 899/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1303 - accuracy: 0.9625 - val_loss: 0.2637 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 900/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1394 - accuracy: 0.9517 - val_loss: 0.2638 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 901/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1361 - accuracy: 0.9529 - val_loss: 0.2687 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 902/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1353 - accuracy: 0.9510 - val_loss: 0.2685 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 903/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1442 - accuracy: 0.9542 - val_loss: 0.2688 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 904/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1351 - accuracy: 0.9587 - val_loss: 0.2700 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 905/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1453 - accuracy: 0.9504 - val_loss: 0.2725 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 906/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1424 - accuracy: 0.9523 - val_loss: 0.2681 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 907/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1270 - accuracy: 0.9580 - val_loss: 0.2687 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 908/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1309 - accuracy: 0.9612 - val_loss: 0.2679 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 909/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1535 - accuracy: 0.9497 - val_loss: 0.2683 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 910/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1422 - accuracy: 0.9497 - val_loss: 0.2703 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 911/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1365 - accuracy: 0.9587 - val_loss: 0.2678 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 912/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1355 - accuracy: 0.9548 - val_loss: 0.2681 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 913/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1430 - accuracy: 0.9542 - val_loss: 0.2662 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 914/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1353 - accuracy: 0.9574 - val_loss: 0.2691 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 915/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1305 - accuracy: 0.9517 - val_loss: 0.2646 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 916/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1308 - accuracy: 0.9542 - val_loss: 0.2623 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 917/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1520 - accuracy: 0.9485 - val_loss: 0.2625 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 918/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1538 - accuracy: 0.9478 - val_loss: 0.2629 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 919/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1331 - accuracy: 0.9606 - val_loss: 0.2642 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 920/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1393 - accuracy: 0.9580 - val_loss: 0.2655 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 921/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1421 - accuracy: 0.9574 - val_loss: 0.2654 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 922/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1365 - accuracy: 0.9574 - val_loss: 0.2634 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 923/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1376 - accuracy: 0.9523 - val_loss: 0.2643 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 924/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1308 - accuracy: 0.9574 - val_loss: 0.2630 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 925/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1396 - accuracy: 0.9548 - val_loss: 0.2620 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 926/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1308 - accuracy: 0.9555 - val_loss: 0.2663 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 927/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1401 - accuracy: 0.9606 - val_loss: 0.2672 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 928/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1450 - accuracy: 0.9472 - val_loss: 0.2649 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 929/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1412 - accuracy: 0.9485 - val_loss: 0.2632 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 930/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1417 - accuracy: 0.9529 - val_loss: 0.2602 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 931/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1322 - accuracy: 0.9599 - val_loss: 0.2624 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 932/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1331 - accuracy: 0.9548 - val_loss: 0.2626 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 933/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1418 - accuracy: 0.9548 - val_loss: 0.2613 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 934/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1272 - accuracy: 0.9618 - val_loss: 0.2628 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 935/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1451 - accuracy: 0.9517 - val_loss: 0.2639 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 936/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1280 - accuracy: 0.9599 - val_loss: 0.2650 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 937/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1399 - accuracy: 0.9555 - val_loss: 0.2647 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 938/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1227 - accuracy: 0.9669 - val_loss: 0.2628 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 939/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1375 - accuracy: 0.9580 - val_loss: 0.2620 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 940/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1462 - accuracy: 0.9504 - val_loss: 0.2667 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 941/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1428 - accuracy: 0.9504 - val_loss: 0.2706 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 942/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1314 - accuracy: 0.9612 - val_loss: 0.2655 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 943/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1441 - accuracy: 0.9542 - val_loss: 0.2703 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 944/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1381 - accuracy: 0.9491 - val_loss: 0.2678 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 945/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1328 - accuracy: 0.9587 - val_loss: 0.2659 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 946/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1367 - accuracy: 0.9561 - val_loss: 0.2677 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 947/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1347 - accuracy: 0.9574 - val_loss: 0.2648 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 948/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1474 - accuracy: 0.9485 - val_loss: 0.2621 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 949/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1449 - accuracy: 0.9574 - val_loss: 0.2631 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 950/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1431 - accuracy: 0.9510 - val_loss: 0.2675 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 951/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1283 - accuracy: 0.9637 - val_loss: 0.2647 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 952/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1345 - accuracy: 0.9580 - val_loss: 0.2673 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 953/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1339 - accuracy: 0.9580 - val_loss: 0.2625 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 954/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1373 - accuracy: 0.9599 - val_loss: 0.2663 - val_accuracy: 0.9353 - lr: 1.0000e-05\n",
      "Epoch 955/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1456 - accuracy: 0.9472 - val_loss: 0.2624 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 956/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1283 - accuracy: 0.9567 - val_loss: 0.2620 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 957/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1392 - accuracy: 0.9536 - val_loss: 0.2663 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 958/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1484 - accuracy: 0.9504 - val_loss: 0.2661 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 959/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1306 - accuracy: 0.9606 - val_loss: 0.2634 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 960/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1355 - accuracy: 0.9542 - val_loss: 0.2635 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 961/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.1428 - accuracy: 0.9510 - val_loss: 0.2662 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 962/1000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.1283 - accuracy: 0.9618 - val_loss: 0.2658 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 963/1000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.1470 - accuracy: 0.9453 - val_loss: 0.2657 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 964/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1291 - accuracy: 0.9612 - val_loss: 0.2653 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 965/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1416 - accuracy: 0.9567 - val_loss: 0.2638 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 966/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1354 - accuracy: 0.9542 - val_loss: 0.2652 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 967/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1338 - accuracy: 0.9504 - val_loss: 0.2670 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 968/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1414 - accuracy: 0.9536 - val_loss: 0.2623 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 969/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1302 - accuracy: 0.9523 - val_loss: 0.2639 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 970/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1312 - accuracy: 0.9618 - val_loss: 0.2621 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 971/1000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1480 - accuracy: 0.9478 - val_loss: 0.2621 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 972/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1291 - accuracy: 0.9656 - val_loss: 0.2633 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 973/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1402 - accuracy: 0.9466 - val_loss: 0.2681 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 974/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1408 - accuracy: 0.9529 - val_loss: 0.2666 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 975/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1371 - accuracy: 0.9536 - val_loss: 0.2657 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 976/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1382 - accuracy: 0.9606 - val_loss: 0.2686 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 977/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1343 - accuracy: 0.9542 - val_loss: 0.2707 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 978/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1240 - accuracy: 0.9631 - val_loss: 0.2710 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 979/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1585 - accuracy: 0.9447 - val_loss: 0.2738 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 980/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1440 - accuracy: 0.9523 - val_loss: 0.2712 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 981/1000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1356 - accuracy: 0.9555 - val_loss: 0.2739 - val_accuracy: 0.9353 - lr: 1.0000e-05\n",
      "Epoch 982/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1333 - accuracy: 0.9561 - val_loss: 0.2738 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 983/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1290 - accuracy: 0.9631 - val_loss: 0.2736 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 984/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1371 - accuracy: 0.9567 - val_loss: 0.2753 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 985/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1364 - accuracy: 0.9580 - val_loss: 0.2725 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 986/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1389 - accuracy: 0.9517 - val_loss: 0.2679 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 987/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1428 - accuracy: 0.9523 - val_loss: 0.2726 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 988/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1422 - accuracy: 0.9497 - val_loss: 0.2704 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 989/1000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.1362 - accuracy: 0.9542 - val_loss: 0.2677 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 990/1000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1186 - accuracy: 0.9682 - val_loss: 0.2667 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 991/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1401 - accuracy: 0.9548 - val_loss: 0.2687 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 992/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1342 - accuracy: 0.9574 - val_loss: 0.2660 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Epoch 993/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1471 - accuracy: 0.9536 - val_loss: 0.2700 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 994/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1415 - accuracy: 0.9542 - val_loss: 0.2719 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 995/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1461 - accuracy: 0.9536 - val_loss: 0.2750 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 996/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1294 - accuracy: 0.9612 - val_loss: 0.2732 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 997/1000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.1391 - accuracy: 0.9555 - val_loss: 0.2722 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 998/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1295 - accuracy: 0.9644 - val_loss: 0.2737 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 999/1000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1490 - accuracy: 0.9542 - val_loss: 0.2767 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 1000/1000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1398 - accuracy: 0.9574 - val_loss: 0.2768 - val_accuracy: 0.9317 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1f938bb4ac0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "r = LSTM_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = test_dataset, \n",
    "    epochs = 1000,\n",
    "    callbacks = [tb_callback, reduceLR_callback, checkpoint_callback]\n",
    "    )\n",
    "LSTM_model.load_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss:\n",
    "plt.plot(r.history['loss'], label = 'loss')\n",
    "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhF0lEQVR4nO3dd1zU9eMH8NftYw+RKYp7Ig4UcZQpiWmWtly5SvtpWpoNtRwtxSzNSsu0rG+laZa2NEtRK5XcuPcCBygqe9z6/P74wHEHB9wBxzFez8fjHt59xn3e9wH5vO69PhJBEAQQEREROYjU0QUgIiKiuo1hhIiIiByKYYSIiIgcimGEiIiIHIphhIiIiByKYYSIiIgcimGEiIiIHIphhIiIiBxK7ugCWMNgMODGjRtwc3ODRCJxdHGIiIjICoIgICMjA4GBgZBKS67/qBFh5MaNGwgODnZ0MYiIiKgcEhMT0aBBgxLX2xxG/vnnH7z//vs4dOgQbt68iU2bNmHw4MGl7rNr1y5Mnz4dJ0+eRHBwMGbPno2xY8dafUw3NzcA4odxd3e3tchERETkAOnp6QgODjZex0ticxjJyspCWFgYnnnmGTz22GNlbn/58mUMHDgQEydOxJo1axAbG4vx48cjICAA0dHRVh2zoGnG3d2dYYSIiKiGKauLhc1h5KGHHsJDDz1k9fYrVqxA48aNsXjxYgBA69atsXv3bnz44YdWhxEiIiKqvew+miYuLg5RUVFmy6KjoxEXF1fiPnl5eUhPTzd7EBERUe1k9zCSlJQEPz8/s2V+fn5IT09HTk6OxX1iYmLg4eFhfLDzKhERUe1VLecZmTVrFtLS0oyPxMRERxeJiIiI7MTuQ3v9/f2RnJxstiw5ORnu7u5wcnKyuI9KpYJKpbJ30YiIiKgasHvNSGRkJGJjY82Wbdu2DZGRkfY+NBEREdUANoeRzMxMxMfHIz4+HoA4dDc+Ph4JCQkAxCaW0aNHG7efOHEiLl26hNdeew1nzpzBp59+ih9++AEvvfRS5XwCIiIiqtFsDiMHDx5Ex44d0bFjRwDA9OnT0bFjR8ydOxcAcPPmTWMwAYDGjRtj8+bN2LZtG8LCwrB48WJ88cUXHNZLREREAACJIAiCowtRlvT0dHh4eCAtLY2TnhEREdUQ1l6/q+VoGiIiIqo7GEaIiIjIoRhGiIiIyKEYRoiIiKoRQRCQq9Xb5b1ztXp8/vdFXLiVaZf3Ly+GESIiO7h2Lxs6vaFc+wqCgMS72ajI+IIcjR630nPLvT8AaHQGzN98CrvPp1TofUpy7V42dp69ZZf3rgx7L6YgPjEVuVo9YracxonraVVy3Be+P4Lwd7cjuRw/vxupOZj7ywlcum05bHy68wJi/jiDAR/9C0D8GV9PtXxrlqrEMEJEDmPPb3/2VvQYGp0B+y/fhUZnwK6zt9DzvZ14Y9MJXE7JKnZRyczT4cCVuyWGjaXbz6PXop34Ju4qDifcQ3qu1my9IAjI05X+GQcv34OuC2JxM630C41ObyixHOsPJmLVv5fx9Jf7zJYbDAIOXLmLbI0OAHA0MRV3MvOQeDcbF0u4CFrS872dGPfVAey/fBcAkJajxaGr9yyW5+9ztxH+7jZsO5VcbB0ghq/Vuy8j8W42/jl3G5O+O4TzyRk4n5xRbNv4xFT837cHSyyrIAi4nZGHEav2YfDyPYjZchqf/3MJD3+y27iN3lC8jIl3s7Fsx3kk3s02LrMlkGZrdNh/+S5+P3YTmXk6fBN3xWz/8f87iEeX7YZGV7gs4U42Lt3OhN4gwGAQ0H3hDnwTdxVPf7EPvx29gSlrD+PkjTQ8v+YQLt3OxN6LdwAAmvz3nbL2MHos3IGjialWl9Me7D4dPBHVXanZGihkUrioiv+p2X0+BWO/2o+ZD7WCp7MSa/ZdxedPd4avu7rE90u4k43dF1JwLjkD97XwwQMtfSGRSAAAF25l4qs9l9G5kRdmbTyOp7s1wpyH2xR7D53egDtZGhy+eg+hDTzQwMu5zM8hCAKOX0/D5ZQsPNQuADvO3MLktYexYEg7DO3SEACwYMtpfL33Cp7v3RT/nL8NQLyYrz+YCB9XJQ7OfhBnkzKQmafDJzvOY9fZ21j8ZBge79yg2PE+ij0PAJj360kAgI+rCrtnPAC1QgYAGPvVAZy8kYadr/SGm1qB1GwNlm4/jx7NfPBAy/q4mZaLs/kX4c//vgRBEDA1qgW8XZQAgLNJGdh4+Bq6NamHCd8cxIt9m2NS76a4fi8HKoUUAR7irTqu3Su8qBoMAqauj0c9FyVa+Lnh9U3H0b+tPx7v3AATvjmIFn6uOJcsXtyPvdkP7mpFiefy9U3HkZKpMS7bdfYWujb2xtNf7MPx62lYNTocqdkaCAAGdwiCUi7F5DWHkZmnw4RvDuLKwoHIytNBozPAy0WJS7cz0Wfx3wCAHw4m4kyS+Nn/OJEEAPhkeEcMDA1AckYuZFIJBi/fAwBwUyvwwZNhxs93OikdS7efx7ZTyYho7G0s30+Hrxuf6w0CYracxhe7L2Ns9xBo9QYM79oQs38+gfj8C/qVO9l4fUBrnLyRhvH/O4hnejbGxPubwsNJgYQ72Zi6/gj+776m6N/OH9/GXcH207fQr60f3th0wuxcLd95EVuOJ2HN+Ah4OSux/bQYxAZ8/C+WDu2AWRuP43h+bU1okAeGd21o3PdGWi5e+P4IAOD3YzfFn8u1NAR4FP7/WvnPRfyVH+6+3nsFHw7tYPFnVhU4zwhRLZWr1ePkjTR0CPaCTCoxW5en00Mll1ncr7R1triXpcGDH/4NP3c1Nr/Yy2zdB3+exbKdF4rtM6RjEB7tEAiNzoB/z6fgr1NJSE7Pw4IhoRgR0RAt3vjD+I0OAOY83AZju4dAJpXglQ1H8eOha2bvd/rt/vjt2A008nZGiI8L0nK02HzspvFir5BJcH7+AOP2BoOAo9dS4aaWY/2BRPx5MhnfPNMVGw9fw8c7xPLO6N8Kn+68gIw8sVbg0oIBEAA0fX2L8X2a+7rifJE2+TPv9EerOVuLfebDcx5EVp4OBkFAsJczpFIJQmZuLrZd20B3/P5CT+TpDMb3GRoejPeeaI+1+xLw+qbjxX8IRUQ09kZzP1dsP3ULSUVqa4Z1Cca6A4U3Je3RrB7CGnji010XAQCPdQrCRpOLcmke7RCIsd1D0MTHFc4qGa7dy8HHseex6UjJ+68dH4ERX+wrtvyFPs3wcr+WaPr6FmNtxK9TemDOzydwKSULO1/pjW/jrhp/piVxVsqQrTGvTXJTy/He4+0xf/NpGAQBN9PKbhbxcFIgLUdb6jZBnk5Iz9Eaf0cK9G3lCw8nBTaWch7sTSmTmv0fMvXblJ4IbeBRqcez9vrNMEJUSxVcnGcPbI3xvZoYl7/7+yl8+99V/PZCT7TwczPb5/djNzBtXTzef7I9hnQs/o19x5lk7L98D5PubwoPZ8vffAuYXiAPz3nQ+K0cgMWLLQA083UtsWPd2gkRGLGq+MXKSSGDi0qOlMy8YuvCGnjg6DXxm2OghxpJ6bkoWrt+6u1oOClk+Od8Clbvvoy/z90u8T0sCfRQ406WBnm60qvjH+0QiF/ib5S6DQBMf7AFlmw7Z3Hd6wNa4cvdl5GcXvhZvV2UuJulsbh9deDvrobOYDCrCbFVmwB3nLqZXomlIkt+mdwDYcGelfqeDCNENYggCNDqBSjl5evGte1UMt789SSWPBWGiCb1YDAIaJL/Td1ZKcOpt/sDEGtLCr5V+7ur8fajbeHupMD3+xPw5qC2CJ+/3fjt83LMAGMTCABcvJ2JvvlV4QDQtbE3Hm4fgP5t/bH1ZBL6t/U3NrEcTUzFo/lV4YAYMgwGAY93boD3/zxbrs9oL4Eeani7KnHiOi92VLoPh4bhpfVHja8f6xhkVssxJrIR/hd31RFFqzA3lRzH3uxn9n++MjCMENUQRxLuYcine6GUS/Hvaw/Ar4Q+E9fuZeNsUgYOXr2He1kaLBgSCml+80vzN7ZAqxf/K3/3bATW7LtqbC8HgOfua4K+rXyx9WQSvtpzxapyvdinGUJ8XDD9B/GPb7sg9zIv2H+9dB8aejvjoY/+xeWULKuOU5sFeTqVOlJhzfgIjLTQNFGVWvq5GfuX+LqpoNUbcC+79GaIqnBfi/r4p0gtVWmCvZ0w5YFmmPFT6c1VjX1ckKPR48ux4fji38v4Jf66sbasgZcTrt0z/3l9+2xXbDh4DSMjGiKiST0s33nBGKivLByI88kZePDDfwAAG5/vjsc+3WtVeXs0q4c9F+6YHbOgFs5NLUdGrq6Md7DNd89GmHVEfq1/S5y6kY6H2wdAKZeiXaBHqf21yothhKga++FgIs4mZeD1Aa3N+hqEN/JCoKcTnu7WCK9sOIoREQ0x8f6mAICOb/9ldpH4bGQnxJ65hQda+mLy2sN2KaeldvbqpOjFvoGXE26k5hRriinJk50bICNXh60nk4qta+XvhuZ+bvjtqNi08kq/FvjgL8vNJwDw8oMtsNikeeXbZ7uie1MfdH53G1JLuLhfmP8Q/r2QgnFfHbCuwDZ6pkdjSCTAl7svG5e9/WhbdGtSD0qZFDvP3kJk03rov1Qc5unprICTQlZm34lxPULwbdxV6AwCAj3U6BzibTxPBUz7JtRzUeJOflPS0PBgtAl0N3bOjX35fnzw51mz8CyTSrDz5d44dTMNK/+5hMMJqcXK8O2zXREW7Imbqbm4kZqDdkEecHeSo88Hf0MiAR5uH4itJ27i7UfbYfTq/cb9zr37EORSiTHI52r1iE9MRWq2Bv3bBQAAwt/dbmz2u7JwoNlxNToDZm48hm5N6uGp8GAAwI+HrsHfXY2ezX1w7V42Nh6+jrtZGqRma3AnS4NDV+/h/SfCkHA3G+9tPQMA2PR8d3Rs6IXv/ruK2T+LHVe3TusFgwGo76bCL/HX8dPh6zhdpHlq3qA2eOu3UwCAR8IC8avJeR/cIRA/mzQFdg3xxv4r4kilSwsG4N8LKfi/bw9ifM8meCW6paUfbaWz9vrN0TREVSw9V4vXfjwGALhSpPbg4NV7wNV7xj8wC/84YwwjRb+tTlojBpCinTYrkyOCSLcm3nihT3Psu3wXH8eeR49m9fBohyDjOTP15dhw44W0obcztkzthcxcHU7fTEfXxt5ISs/FKxuO4khCKp7s3AAbLJyrz57uhFsZefjrZBI2H7+JhY+1x8kb6ejb2hf/nLuN347egIeTAqO6hZQaRga2DzCGkdiX70fT+q4AxG+kPx66hq/3Xim2j1wmxQMtfXF4zoPos3gXtDoDskzO+dF5/bDr7C28suEoBoUFWuxAGt7IS/y9AfDO4Ha4kZqDz/I7nc4dJI4mKggjo7o1wujIEOO+43wam72XVmfA8hGdMGb1frwa3RIxf4gXzpB6zlg2ohPquSrh766GRCLBE50bYM7PJ/DGwNYIDfJEn1b1jU0YHw3rgH5t/PFR7Hk8EhaINoHuZv2ERkc2QrZGj2BvJzSt74rPnu6M1bsv493Np7B0WEd0CfFCgIcTGtZzRv92AZi85jD2Xb6DqX2bY84vYohpWt8V7moF3P0VaOlf2Pfpj2liZ2l3tQIzH2pl/Nzf/ncVaoW0WFOoWiFDtyb1zJaV1lKhlEux5KkOZsueMBkR1cDLGS/2bW5xX0EQ4KqSISk9F2ENPAEAfVv74qfDnhjQLgCt/Asv1uN7NcH4Xk2MI9J2nb2NTo08Uc9FhR1nbqFjsCem92uJa/eycTghFQ+0rI+lwzrivhb1Mf2Ho2jh54rOIV7GMCKVSnB/i/o4885DJX84B2LNCFElMxgE47cuUzdSc6A3CDh2Lc2mmozvJ3TDsWupxgtDScIaeOD1Aa0xfuUOeEoykCj44YGW9bHzbPGq7uNv9kP3hTuQkatDPRclZj/c2nghaVTPGU+FB1vs29GonjOu3hGHewYiBc/0CcW7O25aLM9LUS0wqXdTtJj9BwCgQ7AnfFyVUMll6N2yPj746yye7BxcbFTNylGd0a+tPwDg0NW7aObrBne1HEu3n8fHO84jqrUfQoM8kJGrxRsD2xgvcve1qI9vnularBwZuVpjmU3niQCAV6NbYvIDzUo+qRD7vzTwckI9V5XZBVUhk6Bbk3rQ6g0Y1qUhBncMwtu/nUI9V6XF90xKy8XcX05gbI8Q3MnUIMBDjfCQwuGjuVo9VHIptHoB/+YPDe7b2s+4Tq2Q4UpKFrafTsaynReMtS1XFg7EDwcTsfdCChY9EYYbqTno/cEutG/ggV+n9AQgdjzecPAa5g8JNetIXCD83W1IydSgd8v6+HpcV+PxLqdkYeeZWxgd2QhyWdn9mQrmXikYgmyq4NxN6NUYbwwsPuS64FJkqc+CIAiQSCTYfOym8f/OmXf6WzxOSU7dSIePq9KqpohFW8/g010X0amhJzY+38PqYzjCrYxcbDp8HU+GBxt/thqdATKpBBm5Wry+6TiGdGyAB9v4OaR8bKYhcoA3Nh3HnyeTsGFidzT2cQEgzrWhMwjou/hvpOdq0blh4TfZyjSqWyO8M7gddEvaQp5+DZrJRyB4NULMljOQSiTYd/kOTt5Ix8DQACwf2Ql5Oj3+PJmMqNa+cFbKcfF2Ji7dzsJ9LXygksvQZNbmYs0dcbP6YP/lu/jn0HEsThwKwckL2dMuIE9nwJmb6dh3+S4a+7hgUFigcThxwUXosY6BWDK0o/G9Ci4wBZ1d3dRyfDK8I3q39C3xMyal5cLLRSEOPRYEQCLBUyvisP/KXax/rhsiinzDNZV4Nxu9Fu0EAHRu5IWwBp54NbolnJQWLmj5713UvF9O4PsDidjyYk8083Urvl8V6bFwh7F5qmgzAiCeJ09nhdUX6wu3MvBt3FU8/0CzEvssVdR3/13FT4ev4csxXSwGImv8cfymsUbQ0ueuLLlaPf48mYSezXxQz1Vlt+PUBQwjRJVIbxCKzdVhatmO8/jx0DVcyf8GHtmkHr5/rhsW/nEGK/6+aNUxnujcAEcTU4vNT2GtTc93R8cGHsDbXuKChz8Ewp8xrr+Vnot1BxLxdLdGhRcDXR7w9cOAZ0PgiS+B89uAnycBj3yC/n+4GCeP+r/7mqCeqxLP3Sc2GeHYBmDjePH5vNRS67U3fPQynrz3RX6ZlgLh44ptcz45Ax7OCvi6WXkhPLMF+O1FYPBnSAm4DymZeWZV3Jak52rR/s2/AAArnu6M/u38LW+o1wFf9QecvICRG8xWifcMMVgOMGURBGD900BGEjDmN0BZ9mRrJTl09S7+79tDeGNga4tDsKuNH58B7lwExv4OqGwIbwn7gA1jgYEfAK0Giudu3QgYMm9hYNpraNvI3zhZWbXy8/PAzWPi53XytM8x4r8Hts8DnvoWaBhR9vbXDgLrRgB95gCdRtmnTKVgGCGqBIcT7mH4yv+QpzPgp0mRaO7nBjeV3FiVfCM1BxO+OYiTN8w7mYU18MD/3d8Uz6+xvjnm0oIBkEol+OnQNSz+6yy6ZmxHF+lZ/M/zeXxW7wc0vboez2texBZDN7P9fn+hJ9JztOjezAfIvAV8kN9e/cgnQKfR4vP0m+If98T/gOBuwJNfA+4B4h+qL/qK20yKAz7vBRjyp/hWhOFMjhfm6Mbh3PMBwMEvgX7vAq6+wP5VwJZXxP1ev2l+Yc2+C2ybCwR1BhLigGPrzT9osyggLxO4dRoY9h2QuB+4cUT84x29QPwM3w8D7lwAWj0MDPlc3Db2LeDKv4DSFdCYBLaJu4G/3wNyUsX1je8DDAYxIBn0QMJeoPH9EPQaHL+ZBb1BQPsGnpBlpwC3TwMh+ROyXfkX8A8FslKAjPymp0EfiReX6AViGWPfBq4fBJr2AXzbiH/gpfnNF4IA7IoBEv4DpDJxm5tHgYiJwKGvxItyQpy4rX97IPkEIBiABl0AqVxcF2I+OVwxifsBjyDAPQgCAGMEzL4D3BI7NaJRD+DqHrF8zvk1RdocsdwhvcRyXt0NSKSAsw+QdQvwCAa8m4jlKarx/UDSMSCnlNq8K/8Cfu3EAGfQiZ+loBwA4NsWcPYuvl9OKpB8vPjnvvKv+evgbuLvLgAhIAwSlTuQfh1Iuw4EF2+as6sbRwAnb8CrUfF1BeX2aSn+Pymq5QDxHP08EWgYKf7cSzoHRWUmi79Dgkk/LtN9EvcD+jwgsBOgdCleJgCQKsRy38lvGm3UQ/w9KDDgA8C3VenlsBHDCJEV0nK0eP/PM4hs4oOB7QOMyxPuZMPDWYGwt/4qtk+bAHf4e6jxz7nb0Jm0Y/STHsB1oT5OCiElHs9VJYdWp8Wvva4h0z8Cj68r7PlurHY+96d4ESkICWEjgKNrjduF5IrPg3AbHaQXsfyFJ8SLUdM+wLVDwBd9xA0ffBtoMxg49QuwcwGgKzLE9PEvgeuHgP8+FV93fQ7Yv7JYmbfqu6C/LH+0h08LIGwYcGazuC8g1r64BYh/XBv3Er/9n/6txHNQqqJBAwA8GgIyBXDXuhomu2j1MHDm9+LLg7uJ4UoiEUPYf8urvmxUg0gAVONL7rPbgeAulfqWDCNEJi7ezoROL5j1ugeAkV/8hz0X7sDbRYmx3UMwuEMQtAaD2eRepurjHu7CHXqYV9OHSi7hN9VsAIVhoahPhndERBNvuB1dDaftswCpHC+3/As/HUlCK383bJ12H5B2DfiwrfmOHsFAWuE03YM8fsLQJnkYfHQiXA0mNTLDvgcS9wF7loqvm/YF8tKBa/YZNmrR6F+Abx6tuuOVptvzYigyOXfwbgo88Lr4/KdnxX+7vyjWCMQts295woaLwUUQxCC37zNxuVQuhs/MZPFn1mGE5f3vXgZ2vis+f+wL86axgs9S1ONfiv/+/Lz4rbnd40DyKbFGyJJWDwNthxS+3rUQuJM/zXrPl8Taj6JMA+3jXwJ/vgFkJonhuMPIEvvfmJW763NAcH6Tg2AANk6wXK6C9xKEwmbCB2YD3uajguwm4ybwl/j/HENWijVgpgpq4yQWOvvuWQokmcyB4lIf6L/Q8jmwpGC7+14F6hepvUg+CexeUvi64OdeQBDE2pC/F5ov92wE9J1b+LrJA4BLyf2uyoNDe4nyafUGPPbpXqTlaLF7xgPGG6Pp9AbsuSDewfJulgZLtp3Dmn1X8fKDlsff95EexheKxfhMPwjv64aZrWsnvWxxnwIn34ouvFncmY3ivwYd5nhsRdP+QzEyIr/KN8PCHUlNL6YAfkt7HDhi4SDrhpu/vhhbaplK1OQBQO0u1qjYyp5BxMkbaBAu9ifIM5mevc1g8SJZcKEGgPteA+5/TWwiOfKd2GR0YZvYbBWQ39fAzV9sguk2Sfxj7R4o1jD9u7j4sd2DxGaBknR8WrwApV0H5GqgXlMgNw24GS82yTh5imVS5/8xbvc44FofuBoHRL0JKJyAYz8A3V8AVK6WjyEIYlOHVyMx1Jhy8wcu/yNeCMPHiT+7gA5ASP5IkPqtgHN/iMEr557YzFZwIT32A3Av//e350viOS5Qrylw+BvA1R+475XiF18AaPuYeH6COgONIoGgTsDRdfmfpYx+Ip4NxWatyMnm7+3kBez7XGzCAoAeL4rnyJSzF3DvqlgzV8mzhpZK7SEGiZY2DpH1bQ0c+FKs+cu+Czz0nnh+PYLFLxFFz0FRLj7A7XNA1wnFP2+7x8X1F2KBPrPFn0FRgiBu49EAuLIbSL0KRMcAnsG2fQ47Yc0I1XpnkzIQvVScIXFG/1aY1LsptHoDfj5yHa9amLti0YAghG0fiauCH1pIrmGRbii2GLrhirrwG6tp7cdSxTIMlhXOutg89xto83P+s7LNeN5tN+pN+kNsd/9rTuE3zQKBHYGUC0BIT/GCUZlc/cRv3GXpMl78QyZTiM0757YCh74u/3GVrmKb+d1L4usmDwCXxJEscPIWjyeVA/FrxD+KMqXYZ+Xw18DJX4C0BOD+GYBcJfbT8GgIDF4u9gcRBOCPGcD+z8Xaj/4x4vsm7BP7lTz8IVC/AhM6JR4Avsy/2Ad2AoZ+K7bV//GaGALcg8R2eIlUbLrp9bL5t8uaRhCAzS+LzwcurtoLO9V6bKahOulKShaeX3MYU/o0w4BQsQ/IL/HXMXVdPABxxs77WtRHcuIF9L39Lb7SR+OC0ADuyMQ0+Ub8oO+NMW4HMFzzk9n7LtI+hdcUPxhfF4SRx6T/YIlyhdm2u1W9MD59PD4ZFYkHf2hhx09bgpYDxW/x2XeASXuAlPPAVwPEb16Rk4H3m5pv/6aFm8DdvQR8Gil+GzXtuKhwFr8975xf8vGHfQ+0yr8T7t+LxP4qz2wVg1hqAvDikQqNJCGimoNhhOqk8f87iO2nxZqANgHuGN41GDfTco23QS+wRjEfPWTiTI7ReQvxnmIlOkjFb/Gb9V0xULYfJdFDipa5X0MFLU6qLbfV57QZCqeHFwKLKrEte9Z1YFm42G790CLxm7pECrx0Sqy+z00XmwGkcrHdXRAAef4QXm2uWMsgkQAnfhKHXAJiNfj47ZaPp8kSw8ePzwAnN4pNHg++Lb6PNhf47nFxVMaD74jrBL24j4tP4XsIAqDXiPvodeJIC4V95rEgouqHYYRqj9x08Ru6zPIt6wsmzwKAoZ/H4czlBKTBBQUDH12RjWyoYUBhp7JjqvFwl2SXu0iP5r2NltJELFKsKnmj0ppIuv6fOLrl8DfWHbBJb7Fz6L2rQHaK2D5/ZY/Yz8HWznuCAFzYLoaaVg9bHnJpSpMFXP5XLINpkMi+K3aObfZg4fBWIiIT1l6/+ReEqrecVLFZYVUf46KsPB3+PX8beoOAvRdT0OHtbVj811lcT81Bu8y9OKp+Di/JxWaWtpIrOKqagDnyb83eNgsV+3b+i2pu6UEEKL2vRquBwMMflb5/2HDgqW+AyCninCGA2HkxqLP4PKRH+UYRSCRA8wfFzpxlBRFAnLOgZf/iNRrO3kCLaAYRIqowjqahak248i8keo3Y+TP5JLBhHC5q/DHq1nN4+cGWWPnPJWTk6fDJjgv44t/L2C39CJAAU+Ub8aHuCTwp2wWZRMA4+Z+INzTFR8pP7V9omUoc3ZBxU2yi6DS6eA2I2t38Il60FmV8bOGohjbVZKgsEZGdMIyQY+l14vj7kJ5AQ5OZRTXZSPjlHfx0Kh0vFSyLXwuknEV7nMWHCh3e2jYaGRCHDraWXMWjwh7Uk5h3xhQK56ismiACiM0pjSLNlxULIx7iv/e9CvzzPjDoY3Fo6r2rwLTj9ptKmoioGmIYIcfa8Taw5yMAEuDN1MLl2+ag4ckvCoMIAH3yaeNUY0NkeyCHHi9oX4QCOvyhmlXsrUMll/C47N9iyyuk/0Jg60zzZWoPcU6JNo8CA5eYd+As0GkMcPh/ha9V+WHkgTfE/iOu9YGmD4jTdjOIEFEdwzBCVUObU3zSIkCcBAhAsSmSLUy4dfPiUTQwmQKhn/QQpDBgg/JNi4csmBG1VIGdxP4bdy4AR783X/fQInEyra8HFC7r+n9Ayjng4OrCZSN/EufKaN6vcFKrovrHiOfgeP7w4ILtJBIxiADiiBM57xBKRHUPe56R/Z3+HVgQZHkSraL3IQHECcCybhdb3ECSYvZaJdHiR+WbxiG55dJntjizZPcXzJd3GAlE/F/hDJaAeBM1qVQcVWLKtxUQ+kTJQQQQO4G2f6rwdQkjg4iI6iKGEbK/H0aJc1D8NrX07RIPiLezP7bO6rfuJL1QsbIV3N1SXmSkSJfxhc+HrAS8QoDBn1ne1tpboze+HwgKBzqPK1dRiYhqKzbTkH3lZVi+LbklBVNwF719eGUzHblScEOrok1IBR1MASBsqPiwxD/U+uPKlcCEct4vhoioFmMYIfvQZAG3zoizfZYkpYK1GvkMggRSiZVz900/IwaNBeJU8cbOpkVrO0zDSFHeTQqfP1vC7KVERGQ1hhGyj+1viTcys8SgF/uKLOtcKYfKhgquyLVuY/f8EDI+VqwdKQgWRWtGVKX0//BpDgxbK97JlFObExFVGPuMkH2UEESeXfQ1st9pgMT/Tai0Q+VCaXy+TGcyQZhfKDbo7rO8U4NwcRRNAdOakdaPFN7TpSStBgINKidMERHVdQwjVPl0mhJXfZk9Fc5CNoJv/llph/vP0Br6+m3xuz4C6/W9C1c4eeJV3UTcEjzLfhOJRLxPS0AH4ImvKq1sRERUNjbTUPnotcD+leJIkk6jzddl3KjSouRBCf1z/2LKnK3ww93CFflNL5Kic5iUZNga8SZyEknZ2xIRUaVhGKHyubgT+PN18bl7INAsqnBdbprlfexEL0ihkIuVfBrTX2mZEk90bgDJCRtuTM0gQkRU5dhMQ+WTm1r4/LvHxbvrGtelV/7xBi4GnttlcZVapYAkP0RoYDKZmFSO959oD+8GLSu/PEREVGkYRqh8DDrz13cvFj63UDPyh76LzYd4JO8dcYr1CTvEScgCO1rcLqptkPG5eRiRQSKRQPr4KqB5NDDuD5vLQERE9scwQqLb54AfxgBJJ6zb3qA3fy0IwMlNMGyaZHEq9+uChZvHleKQoTmOCU2BkRuAoNJHrTirCke+aI230oPYfAQA3o2BkT8AjbrbVAYiIqoaDCMk+mUycOpnYGVvQK8Tb3l/72rhel0eELcc2PEukJVSvGYkLx3YMBbSo2uhi/us2NunCB4wCNb3x5BBb3lF1+fEfxuaBAupSQCBBHcU+XOJhD9j9fGIiMhx2IG1rtNrxcm/0q+Lrw1aIO4TYPubgEwJvHRS3CZ+LbDzXXGbxP1A60Fmb3P6ynW0zn+uS71W7BfrtNAI/TUL4YVMrFIuhrsku9RiKUoKI9ELgHZPiJONfZ4/h4jU/GifNVmO2f1CzGdKJSKiaothpK775lHg6h4xeBQ4+bP4r14DfNC8+D6X/8ZOhOMBk0Vr/j6Gdwvq2SwMXvnb0B6AWDNyXghCZ8n5UouVraqPdx5qW3yFTAE0jBCblQrk319mcIdA/Bx/A0/16QrUs/LmdURE5HBspqmrzv4BLA0VgwggBo8CWSll7v7A5cVmr9+VrjQ+10tkZuti9R0hkxb+qr2snVj6m4f0Qpfnv8SoyJCStzFtmsl//uHQDjjxVjRa+DGIEBHVJAwjddX3w4DUBMvrLHRAtYVEMG9iMUACf/fC6da/eKnIHXBDnzJ/PfZ3wCuk9IOYhpH88CORSOCqYmUfEVFNwzBSW2UkASc3iZ1RCwgCcPo3846plujzKnRotSHH7LUACbxdCpuB6ruqsV7XGwCQ024E8NhK2My09kXKAEJEVJPxr3httaKnWMMRHQNEPi8uO7kJ+HGc3Q8thcHstQFSOCkLw4OLSoamY1fgaOJehPUcUL5ZT00DiFRW8nZERFTtsWaktipoarmwrXDZ5b8r/TD/0z2IDMGp1G0MMG8+kcukCG8WgLAHHjfeP8ZmZs00/DUmIqrJ+Fe8tpPn99XQ5gKHvq7QW/2jDy22TA8Z1uijLGxdyAAJpkU1R+sAdwzrEmx5GxvmIAHAphkiolqEf9Fru0t/A3uXAa6+FX4rAcUDgw4y81lPLTBAivYNPPHH1F4lbqOFHCporS8Mm2aIiGoN1ozUdtos4K83gJtHbd61Xe4X6JD7ufG1pTCihxQ6ofRgsEsfVuax1hnEWUv26ttYVzgJwwgRUW3BmpG6Qpdr8y6ZcIbEpDOqACBVcIGnJKvwbSFDWEh94Hrx/Z/TvAQBEtz0613msd7Tj0Scvg32GtrimDWFYzMNEVGtwb/otZFeV3xZ0XvJWEkwqTwzQIrHNW8iVvWqcVnHRj4IbeJrMYw0bdkej/SLQkNv5zKPo5OosFXf1fqCmTXTWJjylYiIagw209RGmoziy2zsvLpNL94pt0ezesZlAoCLQpBZR1Y/TxfzqeRNzBjUAa0D3OFixURkUlt/E9lMQ0RUazCM1EZ5mRV+iyW6JwAAE+9valxW0GckDwrjsmAfd0hlClgkt37Y7tuPtAMATOrdtIwt89mcXoiIqLpiM01tpC39jrjW0OT/agR7FTaxFISRpbrH8aDsMABArVRCixLCiNLF6uM91SUYvVvWR303VTlLTERENRW/XtZGehuGyJagoPYjxKcwUBSEkWwU3mcGUjkk8uLNNPudegFqd5uO6euuhqQ8s7ESEVGNxjBSG5Wzs6opjaDA9xO6mS0rCCOrJ9xXuFAqh8RCM80pj5LnFCEiIjJVrjCyfPlyhISEQK1WIyIiAvv37y91+6VLl6Jly5ZwcnJCcHAwXnrpJeTm2j7UlKzw9yLg50kVfpvwpv6IbFrPbFnvVn7YPv0+NPb3MVkqQCK30EyjsL6JpsI4mIaIqEazOYysX78e06dPx7x583D48GGEhYUhOjoat27dsrj92rVrMXPmTMybNw+nT5/Gl19+ifXr1+P111+vcOHrNG2OOLNqygXz5TvnA7dOVfjtOzQuPmOrWiFDM183QGEyVFevtdhMo5OXPZyXiIgIKEcYWbJkCSZMmIBx48ahTZs2WLFiBZydnbF69WqL2+/duxc9evTAiBEjEBISgn79+mH48OFl1qZQGXYtFGdWXdYZuBEPGPSAwVDmbtZSqdTFFzaMFP+Vm3Qy1edZHE2jlZXzBnhERFTn2BRGNBoNDh06hKiowhujSaVSREVFIS4uzuI+3bt3x6FDh4zh49KlS9iyZQsGDBhQgWITLv9T+Hzl/cCuGECvqdBbZguFIcPJNIxMOQgMXAx0mSC+Nu1kqtda7DOik1kIM0RERBbYNLQ3JSUFer0efn5+Zsv9/Pxw5swZi/uMGDECKSkp6NmzJwRBgE6nw8SJE0ttpsnLy0NeXp7xdXp6ui3FrBuKBo9/3ge6v1Cht7wLNzhDPO8qpcmkYj7NxUcJ5ZBaaKbRV2nNCDuNEBHVZHYfTbNr1y4sWLAAn376KQ4fPoyNGzdi8+bNeOedd0rcJyYmBh4eHsZHcLDl287XaZZqQXQVqxlJEwo7nSplVv5q6DWQWJiB1SC1PCsrERFRUTaFER8fH8hkMiQnJ5stT05Ohr+/v8V95syZg1GjRmH8+PEIDQ3FkCFDsGDBAsTExMBQQh+HWbNmIS0tzfhITEy0pZh1g6W5RPR5xZcVkSeUMEEZgD0GcRZUnSCFwuowooVUUrxmwiDl5GVERGQdm8KIUqlE586dERsba1xmMBgQGxuLyMhIi/tkZ2dDWmTqbplMbAIQBMvV6yqVCu7u7mYPKsJSGNGVHUayUXJISBB80TfvfUTkLYdcZuXkY/VbQaIoPnLGUML9auyipCYkIiKqEWyeDn769OkYM2YMwsPD0bVrVyxduhRZWVkYN24cAGD06NEICgpCTEwMAGDQoEFYsmQJOnbsiIiICFy4cAFz5szBoEGDjKGEysFgqWak7GaabKjghZLvXXNRCAJgRTPNc3+LnWg7jgJkcszWjsPTsu1oJRVrsQyyKqgZeXYbcO0g0Gaw/Y9FRER2Y3MYGTp0KG7fvo25c+ciKSkJHTp0wNatW42dWhMSEsxqQmbPng2JRILZs2fj+vXrqF+/PgYNGoT58+dX3qeoiyzVglhRM6IR5IAVlR4KeRlhJLCD+Mj3nf5BtJBcM4YRQVoFtz0K7io+iIioRivXFWPKlCmYMmWKxXW7du0yP4Bcjnnz5mHevHnlORSVxGKfkbJrRmZqn8P6Vv8AKeeBJr2Bo2stbmd1nxETcuiNz2W8qy4REVmJV4yaylIzTdKxMncL6dwPGP0LMPVoqXfVVVjbZ8SEDIUdkqW84R0REVmJYaQmyr5ruRZk88tl7vpkeANx0jK50nzyMgA3UXjPGauH9pqQSwpv0CdlFiEiIisxjNQ0WSnAosbl3l2tMO00XJgYfvUchYGPjTG+Lk8zjcKkmUbKNEJERFZiGKlpEixPu28ttcLkR25SM9J7/EKolYVdiMrswGqBzDSMsJmGiIisxDBSE1zcCfz5hjjDqkvxu+mWRi+YhwKV3KRmRFL443d3UkNuUptRnj4jZjUjzCJERGQlhpGa4NvBQNwyYN9nJW6SIRS/F8wJQwjC8laZLXNSWg4jkEghManNKE+fEdMOrBLWjBARkZUYRmqSc38Cgt7iqlTBtdgyKQRkwnx2VPM+I6YbS81mxJVXeGgvwwgREVmHYaS6M50y/+oeYMe7FjfLQPEp2U37cBRQyy33GQEAg8mhytNMk4vCKeCZRYiIyFpVME0mVYimyNTtV/dY3CwDxZtp5BbCiHmNR9HEUJhGFOWYtOwd3dNoJEnGl/qH0JLNNEREZCWGkeou+45Vm+UKxW9MJ4XluyIbScwDh2nNSHmG5l4TfNFf8x4AYA7DCBERWYnNNNVdlnVhRG/hRym3MYyUcBPlcilHKw8REdVRDCPVnZU1I5bCiK+rHJMfaFryTkVqLwRUXhrhpGdERGQthpHqLjulzE3OG4IsjqZRSQW8Gt2qlD3NA0NLPzdbS1fyO7OZhoiIrMQ+I9VV8klg6yxA7WFx9QFDC3SRngMAfKIbjPtkx4tvZNAVX2aqSGBo7ueG756NgL+HqlxFNiVjGCEiIisxjFRX3w8DUhNKXK0VCn90BkghsdTEUsKcJEaS4hVjPZv7WNjQdmylISIia7GZproqJYgA5n1EDJDAdFgufFqK/7Z4qIyD2C8x8N40RERkLdaMVFdSBWDQlrhaD5nJc6l5rBjzG3DmN6D90NKPYcfAwCxCRETWYhiprqTyMsKIac2IFAbTSi43P6DL+LKPYaGZprJwOngiIrIWm2mqo/SbgC6n1E0MkOI3fTdcNATA0LQvjjefhBTBHUt1j9lwINaMEBGR47FmpDr647UyN9FBihe0LwIQcOXZnsjR6LFo6x/o1zbA+uMwMRARUTXAMFIdpSWWuUlhM40YKJyUMsx7pJ1tx7FnnxE71roQEVHtwmaa6khW9jwfph1Yy03tWfH3KAErXYiIyFqsGamO5MVveleUAVJ4OSsw+YFm5T9Ox6eBizuApn3K/x5EREQVxDBSHVlRM+LurMLhmQ9WbNp1uQoYtqb8+xMREVUCNtNUB3otcOwHIPuu+FpuxXTsUnm1uv/L1mm9Sr8pHxERUQkYRqqD36YCGycAf80GMm8D2uLDelfr+pu9lkgroc9IJWrl744X+jR3dDGIiKgGYjNNdRC/pvDfeMvNJgmCr/kCafX70XEKeCIiKg/WjNQQeVCYvZZWs5oRwPzmeNWpCYmIiKo3hpFqLFcoDCB5gnkYEWwJIw9/KP476OPKKFaJTGtGGEWIiMha1a+uvy7JSAauHShxdZLgjRBJMgAgD+bDfTUGG3Jk+DNA6FOAyrVcxbQWK0OIiKg8GEYc6bPuQHZKiauvCT4IQUEYMa8Z0RhsvPLbOYgAbJohIqLyYTONI5USRAAgQ+VvfF40jOTZGkaIiIiqKYaRaszNp4Hx+fvDupqt0+irdxhhJQkREVmLYaQak6lcjM/9vT3N1mkMVVwYIiIiO2EYqcbkameTF+YdWF2d1VVcGiIiIvtgGKkmNELxobpylUkYkZr3GenXNtDeRaoQCQf3EhGRlRhGqolcmN+PZrRmBpSmNSNF5hVxr+Y1I+wzQkRE1mIYqSZyTOYROWEIwT+GMKidCvuMQFLkR6V0ARERUW3AMFJNZAvF79Tr3qq3+ETtWTyMOHnZvUxERERVgZOeVRNFm2kAwMc/GHj5nFgLkn3HfGU1DyNspSEiImuxZqSayCky3TuQP6Opm584e2rRe9E4e1dRycqnbaCHo4tAREQ1BGtGHMWgN3uZY9JMI4GALS/2Mt9eUiSMVNOakX2v98XdLA0a1nMue2MiIiIwjDiOXmP2MrtIM02bQHfz7WtInxE/dzX83Kv3SB8iIqpe2EzjKLo8s5dZKOMCXrSZRmn/G98RERFVBYYRR9FrzV5mC4VhpIGXhSYO05qRUZs4kQcREdUaDCOOos02e2naTOPuZKH1zDSMuPjaq1RERERVjn1GHOH7EcDZzWaLTJtpLNZ5FG2mISIiqiUYRqrSmc3A6d+KBRHAfDQNBAv7Fu3ASkREVEswjFSldSNKXFVmB9aiQ3uJiIhqCX7drgqpCYBgqbqjUI6FGVjNsGaEiIhqKV7h7O2/FcDSUOCv2aVuliXYMLSXI2mIiKgWYRixt7/eEP+NW1bqZuY1IxZqUVgzQkREtRSvcPYmK6P5JV+K4F76BhIJ4N0EUHkA9ZpVQsGIiIiqB3ZgtTe5EtBmlblZk9adgUtlbDT5ACAYxPckIiKqJVgzYm9W1ox8PLq7Fe8lZxAhIqJah2HE3qwID8M1b5gvKGPkDRERUW3CZhp7k5UcRk4aGmG6dhLOCg2rsEBERETVC8OIvclLHrI7UBNThQUhIiKqnthMY2+l1IwQERERw4j9WRFGFgwJrYKCEBERVU/lCiPLly9HSEgI1Go1IiIisH///lK3T01NxeTJkxEQEACVSoUWLVpgy5Yt5SpwjVNCB9aBefONz+9r4VNVpSEiIqp2bO4zsn79ekyfPh0rVqxAREQEli5diujoaJw9exa+vr7FttdoNHjwwQfh6+uLH3/8EUFBQbh69So8PT0ro/zVXwlDe08KjY3PlXJWUBERUd1lcxhZsmQJJkyYgHHjxgEAVqxYgc2bN2P16tWYOXNmse1Xr16Nu3fvYu/evVAoFACAkJCQipW6JpGXPc+ISsY78hIRUd1l01dyjUaDQ4cOISoqqvANpFJERUUhLi7O4j6//vorIiMjMXnyZPj5+aFdu3ZYsGAB9Hp9icfJy8tDenq62aPGstBnRC+Y3+iONSNERFSX2XQVTElJgV6vh5+fn9lyPz8/JCUlWdzn0qVL+PHHH6HX67FlyxbMmTMHixcvxrvvvlvicWJiYuDh4WF8BAcH21LM6sVCzcj9mg/NXhcPI5z0jIiI6g67fyU3GAzw9fXFypUr0blzZwwdOhRvvPEGVqxYUeI+s2bNQlpamvGRmJho72Laj0xh9vK24IFrgnnfGpnUvKaEiIioLrGpz4iPjw9kMhmSk5PNlicnJ8Pf39/iPgEBAVAoFJCZ9Ito3bo1kpKSoNFooFQWb8ZQqVRQqay7p0u1V2Rq93TBGQNC/eHprMTafQkOKhQREVH1YVPNiFKpROfOnREbG2tcZjAYEBsbi8jISIv79OjRAxcuXIDBYDAuO3fuHAICAiwGkVohNRH4Yybw32fiXXZNfK0ehU9HdkZ4Iy8HFY6IiKh6sbmZZvr06Vi1ahX+97//4fTp05g0aRKysrKMo2tGjx6NWbNmGbefNGkS7t69i6lTp+LcuXPYvHkzFixYgMmTJ1fep6hufnsR2PcZsHUmcPo3s1UHnXsBAHxcS6n54Y3yiIioDrF5aO/QoUNx+/ZtzJ07F0lJSejQoQO2bt1q7NSakJAAqbQw4wQHB+PPP//ESy+9hPbt2yMoKAhTp07FjBkzKu9TVDcXdxQ+zyscCZQjKOGkFJurejX3wfO9m6J1gHtVl46IiKhakQhC9f8anp6eDg8PD6SlpcHdvQZcvL9+GLjyb7HFuYICzwb/jjXju1ne700P8d/6rYHJ/9mxgERERPZn7fWbE1xUMScFJzgjIiIyxTBiD3qNxcUSAGqGESIiIjMMI5Ut5x6QfqPE1awZISIiMmdzB1YqhcEAvBdSygaCsQNr6ap9Nx4iIqJKw5qRyqTJLHMT1owQERGZYxipTLlppa6WQIBWz1oPIiIiUwwjlSmv9LsLf6Xvj3vZlju3AgACO4n/hg2vxEIRERFVb+wzUplySw4jv+u74QPdUERmlRJGRv8C3DgMhPSyQ+GIiIiqJ9aMVKZSmmkOKztBCzkebONX8v5qd6BJb0DKfiVERFR3sGakMpXSTPPSg63Q3T0cvVvWr8ICERERVX8MI5WplJoRN7USUaXVihAREdVRbKapTKUN7ZVIqq4cRERENQjDSGXSldI5VcJTTUREZAmvkJVJn1fyOoYRIiIii3iFrEy6wjCyW9/WfB2baYiIiCxiGKlE+vxmmk90g/Gi9gXzlawZISIisohXyMpiMACXdgEANIIcOVAW2YA1I0RERJYwjFRUQafVo99DduccAEALOXKLhhHWjBAREVnEK2RFnP4NiAkCjm0A4tcYF2uggFD01DKMEBERWcRJzypi/dPivxvHmy3WWDqtDCNEREQW8QppBwwjRERE1uMVsiJKCBhawVIYYQdWIiIiSxhGKkKmsrhYAwUAQPvwJ4ULWTNCRERkEa+QFSEvOnxXVNBMo2jQqXAha0aIiIgsYhipiBJqRrQFfUakssKFrBkhIiKyiFfIipBbDiMA8N7joYCEYYSIiKgsvEJWhMxyM037QBcM7dLQvGaEM7ASERFZxDBSEQpni4u9nfKbaUxrQ1gzQkREZBGvkBWhz7O4OMhDHE3DMEJERFQ2XiErQpdbbFGK4A63dtHiC3ZgJSIiKhOvkBWhM68Z+UD7JCLzlqFRgJ+4gB1YiYiIysR705SHQQ9k3wG05jUjuVBCCzm8XfI7trJmhIiIqEwMI+XxzaPAlX+LLc6FGEJU8vwQwgBCRERUJl4ty8NCEAGAvPxp4I3Mwohgv/IQERHVYAwjlUhT9AZ5ps00AsMIERGRJQwjlUgLOd55tG3hAtMOrKwZISIisohhpBI18fPCqMiQwgWsGSEiIioTw0glkiqKTA/PPiNERERlYhipRDJ50TDCmhEiIqKyMIxUIqmiyF18pewzQkREVBaGkUpUvGbE5E69rBkhIiKyiGGkEsmK9hkhIiKiMjGMVCJ50WYaM6wZISIisoRhpBLJS6sZEQxVVxAiIqIahGGkggxCYb8QubKUmhH/9lVQGiIiopqHN8qroGyo4Arx7r0KS800s64BmmzA2buKS0ZERFQzsGakgnJQ2DSjsFQzonID3PyqsEREREQ1C8NIBWlNKpdUqtI6sBIREZElDCMVpDW5U6+Ls7MDS0JERFQzsc+ILTKSgZObzBbpUDjLqquzU1WXiIiIqMZjGLHF98OAG4fNFpk207gxjBAREdmMzTS2KBJEAPOaETcnRVWWhoiIqFZgGKkgszCiZhghIiKyFcNIBeklJh1YlbJStiQiIiJLGEYq6LyqrfG5xPQuvURERGQVdmC1hVQBGLRmi+o3DsW72Q+hQYNgjHVMqYiIiGo0hhFbKJyBvDSzRS7Ozpg9/CkHFYiIiKjmYzONLRTFh+4aJOy0SkREVBEMI7aQKYstauDj7oCCEBER1R7lCiPLly9HSEgI1Go1IiIisH//fqv2W7duHSQSCQYPHlyew1YDQrElDet7Vn0xiIiIahGbw8j69esxffp0zJs3D4cPH0ZYWBiio6Nx69atUve7cuUKXnnlFfTq1avcha2WZGymISIiqgibw8iSJUswYcIEjBs3Dm3atMGKFSvg7OyM1atXl7iPXq/HyJEj8dZbb6FJkyYVKnC1Y6HphoiIiKxnUxjRaDQ4dOgQoqKiCt9AKkVUVBTi4uJK3O/tt9+Gr68vnn32WauOk5eXh/T0dLNHtSAUb6aBYKj6chAREdUiNoWRlJQU6PV6+Pn5mS338/NDUlKSxX12796NL7/8EqtWrbL6ODExMfDw8DA+goODbSmmHZmHEa3cBfBt46CyEBER1Q52HU2TkZGBUaNGYdWqVfDx8bF6v1mzZiEtLc34SExMtGMpbVCkZuTvQXsAZ28HFYaIiKh2sGnSMx8fH8hkMiQnJ5stT05Ohr+/f7HtL168iCtXrmDQoEHGZQaD2Kwhl8tx9uxZNG3atNh+KpUKKpXKlqJVkcIwYhAkcHXjsF4iIqKKsqlmRKlUonPnzoiNjTUuMxgMiI2NRWRkZLHtW7VqhePHjyM+Pt74eOSRR/DAAw8gPj6+GjW/WMdgUjMilQjwcOJIGiIiooqyeTr46dOnY8yYMQgPD0fXrl2xdOlSZGVlYdy4cQCA0aNHIygoCDExMVCr1WjXrp3Z/p6engBQbHm1tzMG0kzzfjHuDCNEREQVZnMYGTp0KG7fvo25c+ciKSkJHTp0wNatW42dWhMSEiCV1sKJXf9eWGwRa0aIiIgqTiIIlsarVi/p6enw8PBAWloa3N0d0E8j6w7wfvH5UYR5qZBIJFVfHiIiohrA2ut3LazCsIMlrSwuZhAhIiKqOIYRa+g1ji4BERFRrcUwQkRERA7FMEJEREQOxTBSXlKbByIRERGRBQwj5SXlsF4iIqLKwDBSXlKZo0tARERUKzCMlBfDCBERUaVgGCmLQW95OZtpiIiIKgXDSFn0WsvL2YGViIioUjCMlKWkCc8YRoiIiCoFw0hZDDrLy2UMI0RERJWBYaQsJdWMSNiBlYiIqDIwjJSFfUaIiIjsimGkLIYSwoiMo2mIiIgqA8NIWUqqGXH2rtpyEBER1VIMI2UpEkZOdP8YCOwIDPrYQQUiIiKqXdjxoSxFOrC2iRoNSMc4qDBERES1D2tGylJkaK9UKnFQQYiIiGonhpGylDS0l4iIiCoFw0gZcnJzHV0EIiKiWo1hpAwp6VmOLgIREVGtxjBShnvp6Y4uAhERUa3GMFKG3KxMRxeBiIioVmMYKYM+O9XRRSAiIqrVGEZKs+9zRJ5d6OhSEBER1WoMI6X54zVHl4CIiKjWYxixRfN+ji4BERFRrcMwUpLM22YvEwKigWFrHVQYIiKi2othxBJBAFb1MVuU4xMKyBQOKhAREVHtxTBiiV4DpCWYLXJycXNQYYiIiGo3hhFLLNyPxsnFwwEFISIiqv0YRizRFQ8jLgHNHVAQIiKi2o9hxJIiNSNj9G/AqUl3BxWGiIiodmMYsUSfZ/byvFNHSKQ8VURERPbAK6wleq3x6ae6R+Ck4igaIiIie2EYsUQn1ozkqX2wSDcMzkq5gwtERERUezGMWJLfZ8QgVQIAnBQyR5aGiIioVmMYsSQ/jOglYo2IWskwQkREZC8MI5bkhxGdROwr4syaESIiIrthGLEkf54RHcQw4sSaESIiIrthGLEkv2ZEm18zombNCBERkd0wjFiSP8+IFmKfEWfWjBAREdkNw4gl+fOMaPLDCEfTEBER2Q/DiCU685oR9hkhIiKyH4YRS/L7jOQa2ExDRERkbwwjluSHkQytBAAQ6OnkyNIQERHVagwjRQkCcCEWAJCqEcNIo3rOjiwRERFRrcYwUlT8GuDCNgBAhk5spgn2YhghIiKyF4aRovavMj7NgwJuKjlcVLxRHhERkb0wjBSVfcf4NBdKuDspHFgYIiKi2o9hpKis28aneYKCYYSIiMjOGEaK0uUan+ZBAQ8nNtEQERHZE8NIKXKhhAdrRoiIiOyKYaQUeVDAXc0wQkREZE8MI0VJC5tlcgXWjBAREdkbw0hRJmFEBxma1Hd1YGGIiIhqP4aRoqSFNSECJOjUyNNxZSEiIqoDGEaKkhbeFE8CAQ29OfsqERGRPZUrjCxfvhwhISFQq9WIiIjA/v37S9x21apV6NWrF7y8vODl5YWoqKhSt3c4QTA+lUkBJwXv2EtERGRPNoeR9evXY/r06Zg3bx4OHz6MsLAwREdH49atWxa337VrF4YPH46dO3ciLi4OwcHB6NevH65fv17hwtuFQWd8qpLLIJFIHFgYIiKi2k8iCCZVAVaIiIhAly5dsGzZMgCAwWBAcHAwXnjhBcycObPM/fV6Pby8vLBs2TKMHj3aqmOmp6fDw8MDaWlpcHd3t6W4tnunPqDXAACGqZZj3ayn7Xs8IiKiWsra67dNNSMajQaHDh1CVFRU4RtIpYiKikJcXJxV75GdnQ2tVgtvb+8St8nLy0N6errZo8rotQCAsZrXkOrUsOqOS0REVEfZFEZSUlKg1+vh5+dnttzPzw9JSUlWvceMGTMQGBhoFmiKiomJgYeHh/ERHBxsSzHLz2AAIFYUHTU04YRnREREVaBKR9MsXLgQ69atw6ZNm6BWq0vcbtasWUhLSzM+EhMTq6aABq3xqQ5yuKp5XxoiIiJ7s+lq6+PjA5lMhuTkZLPlycnJ8Pf3L3XfDz74AAsXLsT27dvRvn37UrdVqVRQqVS2FK1ymHRe1UEKVxXDCBERkb3ZVDOiVCrRuXNnxMbGGpcZDAbExsYiMjKyxP0WLVqEd955B1u3bkV4eHj5S2tvevOakdYBdu4sS0RERLbVjADA9OnTMWbMGISHh6Nr165YunQpsrKyMG7cOADA6NGjERQUhJiYGADAe++9h7lz52Lt2rUICQkx9i1xdXWFq2s1m2rdoDc+1UGKB9v4lbIxERERVQabw8jQoUNx+/ZtzJ07F0lJSejQoQO2bt1q7NSakJAAqbSwwuWzzz6DRqPBE088YfY+8+bNw5tvvlmx0le2/D4jekEClUKOJj4uDi4QERFR7WfzPCOOUGXzjKQmAkvbIU9Q4HGfTfj9hV72OxYREVEtZ5d5Rmq9/A6sOkjh51byaB8iIiKqPAwjpoxhRAZnjqQhIiKqEgwjpkzDCG+QR0REVCUYRkzlD+3VQQYnJcMIERFRVWAYMWVSM+KiYhghIiKqCgwjpgrCiCCDs5J9RoiIiKoCw4gp0z4jbKYhIiKqEgwjpvQaAAwjREREVYlhxFRuOgAgA85wYjMNERFRlWAYMZVzDwCQKrjAhTUjREREVYJhxFRBGIEbh/YSERFVEYYRUzl3ARTUjLCZhoiIqCowjJgyNtO4sgMrERFRFWEYMWVspnHlvWmIiIiqCMOICSG7oJnGlfemISIiqiIMIyY0mflhBK7swEpERFRFGEZMpKYkAwDuCa5QyXlqiIiIqgKvuCY8kAEASIMrJBKJg0tDRERUNzCMFNDmQC3RAhCH9hIREVHVYBgpkD+SRivIkAknBxeGiIio7mAYyafNEsNIOpzRNtDDwaUhIiKqOxhG8mVkiDfJy4EKP03q7uDSEBER1R2c2StfVlYmvAFoJUqoOccIEVGV0+v10Gq1ji4G2UChUEAmq/g1k2EknyY3GwCglagcXBIiorpFEAQkJSUhNTXV0UWhcvD09IS/v3+FRqEyjOTT5maK/0oZRoiIqlJBEPH19YWzszOnVqghBEFAdnY2bt26BQAICAgo93sxjOTT5eWI/zKMEBFVGb1ebwwi9erVc3RxyEZOTuLo01u3bsHX17fcTTbswJrPkJMGANBJ1Q4uCRFR3VHQR8TZ2dnBJaHyKvjZVaS/D8MIAOh1aH/0bQCAQaZ0cGGIiOoeNs3UXJXxs2MYAYCsW8anarAnNxERUVViGAEAFKY6Z+Q4sBxERER1D8MIABh0xqdOAsMIERFRVWIYAQBDYdOMkyHbgQUhIiIqn5o8YRzDCADoC2tGJBLBgQUhIqKaYuvWrejZsyc8PT1Rr149PPzww7h48aJx/bVr1zB8+HB4e3vDxcUF4eHh2Ldvn3H9b7/9hi5dukCtVsPHxwdDhgwxrpNIJPj555/Njufp6Ymvv/4aAHDlyhVIJBKsX78e999/P9RqNdasWYM7d+5g+PDhCAoKgrOzM0JDQ/H999+bvY/BYMCiRYvQrFkzqFQqNGzYEPPnzwcA9OnTB1OmTDHb/vbt21AqlYiNja2M02YR5xkBzGpG9oa+iwEOLAoRUV0mCAJytHqHHNtJIbNpZEhWVhamT5+O9u3bIzMzE3PnzsWQIUMQHx+P7Oxs3H///QgKCsKvv/4Kf39/HD58GAaDAQCwefNmDBkyBG+88Qa++eYbaDQabNmyxeYyz5w5E4sXL0bHjh2hVquRm5uLzp07Y8aMGXB3d8fmzZsxatQoNG3aFF27dgUAzJo1C6tWrcKHH36Inj174ubNmzhz5gwAYPz48ZgyZQoWL14MlUqcd+u7775DUFAQ+vTpY3P5rMUwAgB6MYwkCV5QN+3h4MIQEdVdOVo92sz90yHHPvV2NJyV1l8WH3/8cbPXq1evRv369XHq1Cns3bsXt2/fxoEDB+Dt7Q0AaNasmXHb+fPnY9iwYXjrrbeMy8LCwmwu87Rp0/DYY4+ZLXvllVeMz1944QX8+eef+OGHH9C1a1dkZGTgo48+wrJlyzBmzBgAQNOmTdGzZ08AwGOPPYYpU6bgl19+wVNPPQUA+PrrrzF27Fi7Dr9mMw0AIb8Dqw4yNPTmxDtERFS28+fPY/jw4WjSpAnc3d0REhICAEhISEB8fDw6duxoDCJFxcfHo2/fvhUuQ3h4uNlrvV6Pd955B6GhofD29oarqyv+/PNPJCQkAABOnz6NvLy8Eo+tVqsxatQorF69GgBw+PBhnDhxAmPHjq1wWUvDmhEA6VnZ8ACgFWRo4MUwQkTkKE4KGU69He2wY9ti0KBBaNSoEVatWoXAwEAYDAa0a9cOGo3GOE16iccqY71EIoEgmPdhtNRB1cXFxez1+++/j48++ghLly5FaGgoXFxcMG3aNGg0GquOC4hNNR06dMC1a9fw1VdfoU+fPmjUqFGZ+1UEa0YAJKeKN8mDTAG1jb+MRERUeSQSCZyVcoc8bGmGuHPnDs6ePYvZs2ejb9++aN26Ne7du2dc3759e8THx+Pu3bsW92/fvn2pHULr16+PmzdvGl+fP38e2dllj/bcs2cPHn30UTz99NMICwtDkyZNcO7cOeP65s2bw8nJqdRjh4aGIjw8HKtWrcLatWvxzDPPlHncimIYAZCSlgUAkMgUDi4JERHVBF5eXqhXrx5WrlyJCxcuYMeOHZg+fbpx/fDhw+Hv74/Bgwdjz549uHTpEn766SfExcUBAObNm4fvv/8e8+bNw+nTp3H8+HG89957xv379OmDZcuW4ciRIzh48CAmTpwIhaLsa1Tz5s2xbds27N27F6dPn8b//d//ITk52bherVZjxowZeO211/DNN9/g4sWL+O+///Dll1+avc/48eOxcOFCCIJgNsrHXhhGAKSkiTUjMjnvS0NERGWTSqVYt24dDh06hHbt2uGll17C+++/b1yvVCrx119/wdfXFwMGDEBoaCgWLlxovKtt7969sWHDBvz666/o0KED+vTpg/379xv3X7x4MYKDg9GrVy+MGDECr7zyilU3E5w9ezY6deqE6Oho9O7d2xiITM2ZMwcvv/wy5s6di9atW2Po0KG4deuW2TbDhw+HXC7H8OHDoVbb/wayEqFoo1Q1lJ6eDg8PD6SlpcHd3b3S33/9d59j6IXXcN2lLYJe3Vvp709ERJbl5ubi8uXLaNy4cZVc9Mg6V65cQdOmTXHgwAF06tSp1G1L+xlae/1mB1YAOq3YsQdspiEiojpMq9Xizp07mD17Nrp161ZmEKksbKZJOoGRV2eLz6XMZkREVHft2bMHAQEBOHDgAFasWFFlx+XVd+d841OJjH1GiIio7urdu3exIcVVgTUjSlfjU4mM2YyIiKiq1fkwkqLwNz530qY6riBERER1VJ0PI3+fKxzOpNRlOLAkREREdVOdDyNSfeH0unJdpgNLQkREVDfV+TDiLC0MIzJtlgNLQkREVDfV+TDiJNUbn8t0Zc/7T0RERJWrboeR3DSE5J11dCmIiKgOCgkJwdKlSx1djGqhzo5l1ekNSPu4NxpqLjm6KERERHVana0ZkcukuKL1Ml84apNjCkNERFSH1dkwAgCeAU2Mzy/1eB9o2seBpSEioppi5cqVCAwMhMFgMFv+6KOP4plnnsHFixfx6KOPws/PD66urujSpQu2b99e7uMtWbIEoaGhcHFxQXBwMJ5//nlkZpqPAN2zZw969+4NZ2dneHl5ITo6Gvfu3QMAGAwGLFq0CM2aNYNKpULDhg0xf/58S4dyiDodRkKatjQ+b+Dj6biCEBGRSBAATZZjHjZMg/7kk0/izp072Llzp3HZ3bt3sXXrVowcORKZmZkYMGAAYmNjceTIEfTv3x+DBg1CQkJCuU6LVCrFxx9/jJMnT+J///sfduzYgddee824Pj4+Hn379kWbNm0QFxeH3bt3Y9CgQdDrxUEas2bNwsKFCzFnzhycOnUKa9euhZ+fX7nKYg8SwRGT0NvI2lsQ2+zYD8DGCeLzp74F2jxSee9NRERlKnb7eU0WsCDQMYV5/QagdLF688GDB6NevXr48ssvAYi1JW+99RYSExMhlRb/rt+uXTtMnDgRU6ZMASB2YJ02bRqmTZtmc1F//PFHTJw4ESkpKQCAESNGICEhAbt37y62bUZGBurXr49ly5Zh/PjxNh+rLMV+hiasvX7X6ZoReDQofC5XOa4cRERU44wcORI//fQT8vLyAABr1qzBsGHDIJVKkZmZiVdeeQWtW7eGp6cnXF1dcfr06XLXjGzfvh19+/ZFUFAQ3NzcMGrUKNy5cwfZ2eKUFAU1I5acPn0aeXl5Ja6vDursaBoAgEdw4XNp3T4VRETVgsJZrKFw1LFtMGjQIAiCgM2bN6NLly74999/8eGHHwIAXnnlFWzbtg0ffPABmjVrBicnJzzxxBPQaDQ2F+vKlSt4+OGHMWnSJMyfPx/e3t7YvXs3nn32WWg0Gjg7O8PJyanE/UtbV13U7SuwW0Dh89w0x5WDiIhEEolNTSWOpFar8dhjj2HNmjW4cOECWrZsiU6dOgEQO5OOHTsWQ4YMAQBkZmbiypUr5TrOoUOHYDAYsHjxYmPzzw8//GC2Tfv27REbG4u33nqr2P7NmzeHk5MTYmNj7dJMUxnK1UyzfPlyhISEQK1WIyIiAvv37y91+w0bNqBVq1ZQq9UIDQ3Fli1bylXYSiczyWLuDmqjJCKiGmvkyJHYvHkzVq9ejZEjRxqXN2/eHBs3bkR8fDyOHj2KESNGFBt5Y61mzZpBq9Xik08+waVLl/Dtt99ixYoVZtvMmjULBw4cwPPPP49jx47hzJkz+Oyzz5CSkgK1Wo0ZM2bgtddewzfffIOLFy/iv//+M/Z1qQ5sDiPr16/H9OnTMW/ePBw+fBhhYWGIjo7GrVu3LG6/d+9eDB8+HM8++yyOHDmCwYMHY/DgwThx4kSFC18pJuwEBq8AGnZzdEmIiKiG6dOnD7y9vXH27FmMGDHCuHzJkiXw8vJC9+7dMWjQIERHRxtrTWwVFhaGJUuW4L333kO7du2wZs0axMTEmG3TokUL/PXXXzh69Ci6du2KyMhI/PLLL5DLxS/dc+bMwcsvv4y5c+eidevWGDp0aInXbUeweTRNREQEunTpgmXLlgEQxy4HBwfjhRdewMyZM4ttP3ToUGRlZeH33383LuvWrRs6dOhQLNmVxG6jaYiIyKFKG4lBNUOVj6bRaDQ4dOgQoqKiCt9AKkVUVBTi4uIs7hMXF2e2PQBER0eXuD0A5OXlIT093exBREREtZNNYSQlJQV6vb7YRCl+fn5ISkqyuE9SUpJN2wNATEwMPDw8jI/g4OAStyUiIqrJ1qxZA1dXV4uPtm3bOrp4VaJajqaZNWsWpk+fbnydnp7OQEJERLXSI488goiICIvrFApFFZfGMWwKIz4+PpDJZEhOTjZbnpycDH9/f4v7+Pv727Q9AKhUKqhUnISMiIhqPzc3N7i5uTm6GA5lUzONUqlE586dERsba1xmMBgQGxuLyMhIi/tERkaabQ8A27ZtK3F7IiIiqltsbqaZPn06xowZg/DwcHTt2hVLly5FVlYWxo0bBwAYPXo0goKCjMOOpk6divvvvx+LFy/GwIEDsW7dOhw8eBArV66s3E9CREQ1Vnnn4CDHq4yfnc1hZOjQobh9+zbmzp2LpKQkdOjQAVu3bjV2Uk1ISDC7QVD37t2xdu1azJ49G6+//jqaN2+On3/+Ge3atatw4YmIqGZTKpWQSqW4ceMG6tevD6VSCYlE4uhikRUEQYBGo8Ht27chlUqhVCrL/V51+669RETkcBqNBjdv3jTe9I1qFmdnZwQEBFgMI9Zev6vlaBoiIqo7lEolGjZsCJ1OB71e7+jikA1kMhnkcnmFa7MYRoiIyOEkEgkUCkWdGcpK5sp1ozwiIiKiysIwQkRERA7FMEJEREQOVSP6jBQM+OEN84iIiGqOgut2WQN3a0QYycjIAADen4aIiKgGysjIgIeHR4nra8Q8IwaDATdu3ICbm1ulToZTcAO+xMREzl9iZzzXVYPnuWrwPFcNnueqY69zLQgCMjIyEBgYaDYhalE1omZEKpWiQYMGdnt/d3d3/qJXEZ7rqsHzXDV4nqsGz3PVsce5Lq1GpAA7sBIREZFDMYwQERGRQ9XpMKJSqTBv3jyoVCpHF6XW47muGjzPVYPnuWrwPFcdR5/rGtGBlYiIiGqvOl0zQkRERI7HMEJEREQOxTBCREREDsUwQkRERA5Vp8PI8uXLERISArVajYiICOzfv9/RRaoxYmJi0KVLF7i5ucHX1xeDBw/G2bNnzbbJzc3F5MmTUa9ePbi6uuLxxx9HcnKy2TYJCQkYOHAgnJ2d4evri1dffRU6na4qP0qNsnDhQkgkEkybNs24jOe58ly/fh1PP/006tWrBycnJ4SGhuLgwYPG9YIgYO7cuQgICICTkxOioqJw/vx5s/e4e/cuRo4cCXd3d3h6euLZZ59FZmZmVX+Uakuv12POnDlo3LgxnJyc0LRpU7zzzjtm9y7heS6ff/75B4MGDUJgYCAkEgl+/vlns/WVdV6PHTuGXr16Qa1WIzg4GIsWLap44YU6at26dYJSqRRWr14tnDx5UpgwYYLg6ekpJCcnO7poNUJ0dLTw1VdfCSdOnBDi4+OFAQMGCA0bNhQyMzON20ycOFEIDg4WYmNjhYMHDwrdunUTunfvblyv0+mEdu3aCVFRUcKRI0eELVu2CD4+PsKsWbMc8ZGqvf379wshISFC+/bthalTpxqX8zxXjrt37wqNGjUSxo4dK+zbt0+4dOmS8OeffwoXLlwwbrNw4ULBw8ND+Pnnn4WjR48KjzzyiNC4cWMhJyfHuE3//v2FsLAw4b///hP+/fdfoVmzZsLw4cMd8ZGqpfnz5wv16tUTfv/9d+Hy5cvChg0bBFdXV+Gjjz4ybsPzXD5btmwR3njjDWHjxo0CAGHTpk1m6yvjvKalpQl+fn7CyJEjhRMnTgjff/+94OTkJHz++ecVKnudDSNdu3YVJk+ebHyt1+uFwMBAISYmxoGlqrlu3bolABD+/vtvQRAEITU1VVAoFMKGDRuM25w+fVoAIMTFxQmCIP7HkUqlQlJSknGbzz77THB3dxfy8vKq9gNUcxkZGULz5s2Fbdu2Cffff78xjPA8V54ZM2YIPXv2LHG9wWAQ/P39hffff9+4LDU1VVCpVML3338vCIIgnDp1SgAgHDhwwLjNH3/8IUgkEuH69ev2K3wNMnDgQOGZZ54xW/bYY48JI0eOFASB57myFA0jlXVeP/30U8HLy8vsb8eMGTOEli1bVqi8dbKZRqPR4NChQ4iKijIuk0qliIqKQlxcnANLVnOlpaUBALy9vQEAhw4dglarNTvHrVq1QsOGDY3nOC4uDqGhofDz8zNuEx0djfT0dJw8ebIKS1/9TZ48GQMHDjQ7nwDPc2X69ddfER4ejieffBK+vr7o2LEjVq1aZVx/+fJlJCUlmZ1rDw8PREREmJ1rT09PhIeHG7eJioqCVCrFvn37qu7DVGPdu3dHbGwszp07BwA4evQodu/ejYceeggAz7O9VNZ5jYuLw3333QelUmncJjo6GmfPnsW9e/fKXb4acaO8ypaSkgK9Xm/2xxkA/Pz8cObMGQeVquYyGAyYNm0aevTogXbt2gEAkpKSoFQq4enpabatn58fkpKSjNtY+hkUrCPRunXrcPjwYRw4cKDYOp7nynPp0iV89tlnmD59Ol5//XUcOHAAL774IpRKJcaMGWM8V5bOpem59vX1NVsvl8vh7e3Nc51v5syZSE9PR6tWrSCTyaDX6zF//nyMHDkSAHie7aSyzmtSUhIaN25c7D0K1nl5eZWrfHUyjFDlmjx5Mk6cOIHdu3c7uii1TmJiIqZOnYpt27ZBrVY7uji1msFgQHh4OBYsWAAA6NixI06cOIEVK1ZgzJgxDi5d7fHDDz9gzZo1WLt2Ldq2bYv4+HhMmzYNgYGBPM91WJ1spvHx8YFMJis24iA5ORn+/v4OKlXNNGXKFPz+++/YuXMnGjRoYFzu7+8PjUaD1NRUs+1Nz7G/v7/Fn0HBOhKbYW7duoVOnTpBLpdDLpfj77//xscffwy5XA4/Pz+e50oSEBCANm3amC1r3bo1EhISABSeq9L+bvj7++PWrVtm63U6He7evctzne/VV1/FzJkzMWzYMISGhmLUqFF46aWXEBMTA4Dn2V4q67za6+9JnQwjSqUSnTt3RmxsrHGZwWBAbGwsIiMjHViymkMQBEyZMgWbNm3Cjh07ilXbde7cGQqFwuwcnz17FgkJCcZzHBkZiePHj5v98m/btg3u7u7FLgp1Vd++fXH8+HHEx8cbH+Hh4Rg5cqTxOc9z5ejRo0ex4ennzp1Do0aNAACNGzeGv7+/2blOT0/Hvn37zM51amoqDh06ZNxmx44dMBgMiIiIqIJPUf1lZ2dDKjW/9MhkMhgMBgA8z/ZSWec1MjIS//zzD7RarXGbbdu2oWXLluVuogFQt4f2qlQq4euvvxZOnTolPPfcc4Knp6fZiAMq2aRJkwQPDw9h165dws2bN42P7Oxs4zYTJ04UGjZsKOzYsUM4ePCgEBkZKURGRhrXFww57devnxAfHy9s3bpVqF+/PoeclsF0NI0g8DxXlv379wtyuVyYP3++cP78eWHNmjWCs7Oz8N133xm3WbhwoeDp6Sn88ssvwrFjx4RHH33U4tDIjh07Cvv27RN2794tNG/evM4POTU1ZswYISgoyDi0d+PGjYKPj4/w2muvGbfheS6fjIwM4ciRI8KRI0cEAMKSJUuEI0eOCFevXhUEoXLOa2pqquDn5yeMGjVKOHHihLBu3TrB2dmZQ3sr4pNPPhEaNmwoKJVKoWvXrsJ///3n6CLVGAAsPr766ivjNjk5OcLzzz8veHl5Cc7OzsKQIUOEmzdvmr3PlStXhIceekhwcnISfHx8hJdfflnQarVV/GlqlqJhhOe58vz2229Cu3btBJVKJbRq1UpYuXKl2XqDwSDMmTNH8PPzE1QqldC3b1/h7NmzZtvcuXNHGD58uODq6iq4u7sL48aNEzIyMqryY1Rr6enpwtSpU4WGDRsKarVaaNKkifDGG2+YDRXleS6fnTt3Wvy7PGbMGEEQKu+8Hj16VOjZs6egUqmEoKAgYeHChRUuu0QQTKa9IyIiIqpidbLPCBEREVUfDCNERETkUAwjRERE5FAMI0RERORQDCNERETkUAwjRERE5FAMI0RERORQDCNERETkUAwjRERE5FAMI0RERORQDCNERETkUAwjRERE5FD/Dy1GKtx4pkxqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy:\n",
    "plt.plot(r.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(r.history['val_accuracy'], label = 'val_acc')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2884 - accuracy: 0.9388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2883961498737335, 0.9388489127159119]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model.save('models/LSTM_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models/LSTM_model.h5\")\n",
    "actions = np.array(['pizza', 'burger', 'salad', 'soup', 'sphagetti', 'chicken', 'fish', 'vegetables', 'fruits', 'turkey', 'pork', 'hotdog', 'cheese', 'macaroni', 'pepperoni', 'lasagna'])\n",
    "actions2 = np.array(['sharing', 'platter', 'honey', 'garlic', 'sticks', 'fusion', 'hot', 'fiery', 'ham', 'salt', 'egg', 'basil', 'curry', 'seafood', 'clam', 'mushroom', 'soft', 'crab', 'thai', 'red', 'wings', 'crispy', 'waffle'])\n",
    "actions = np.concatenate((actions, actions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 22ms/step\n",
      "[[[287   0]\n",
      "  [  1   5]]\n",
      "\n",
      " [[290   0]\n",
      "  [  0   3]]\n",
      "\n",
      " [[281   1]\n",
      "  [  0  11]]\n",
      "\n",
      " [[288   0]\n",
      "  [  0   5]]\n",
      "\n",
      " [[283   0]\n",
      "  [  0  10]]\n",
      "\n",
      " [[288   0]\n",
      "  [  2   3]]\n",
      "\n",
      " [[288   0]\n",
      "  [  0   5]]\n",
      "\n",
      " [[280   1]\n",
      "  [  0  12]]\n",
      "\n",
      " [[284   1]\n",
      "  [  0   8]]\n",
      "\n",
      " [[290   0]\n",
      "  [  0   3]]\n",
      "\n",
      " [[287   0]\n",
      "  [  0   6]]\n",
      "\n",
      " [[287   0]\n",
      "  [  0   6]]\n",
      "\n",
      " [[284   0]\n",
      "  [  0   9]]\n",
      "\n",
      " [[285   0]\n",
      "  [  0   8]]\n",
      "\n",
      " [[286   0]\n",
      "  [  0   7]]\n",
      "\n",
      " [[282   0]\n",
      "  [  0  11]]\n",
      "\n",
      " [[287   0]\n",
      "  [  0   6]]\n",
      "\n",
      " [[284   0]\n",
      "  [  0   9]]\n",
      "\n",
      " [[288   0]\n",
      "  [  0   5]]\n",
      "\n",
      " [[287   0]\n",
      "  [  0   6]]\n",
      "\n",
      " [[286   0]\n",
      "  [  0   7]]\n",
      "\n",
      " [[285   0]\n",
      "  [  0   8]]\n",
      "\n",
      " [[287   0]\n",
      "  [  0   6]]\n",
      "\n",
      " [[288   0]\n",
      "  [  0   5]]\n",
      "\n",
      " [[282   0]\n",
      "  [  0  11]]\n",
      "\n",
      " [[283   0]\n",
      "  [  0  10]]\n",
      "\n",
      " [[285   0]\n",
      "  [  0   8]]\n",
      "\n",
      " [[283   0]\n",
      "  [  0  10]]\n",
      "\n",
      " [[284   0]\n",
      "  [  0   9]]\n",
      "\n",
      " [[287   0]\n",
      "  [  0   6]]\n",
      "\n",
      " [[288   0]\n",
      "  [  0   5]]\n",
      "\n",
      " [[283   0]\n",
      "  [  2   8]]\n",
      "\n",
      " [[287   0]\n",
      "  [  0   6]]\n",
      "\n",
      " [[284   0]\n",
      "  [  0   9]]\n",
      "\n",
      " [[286   0]\n",
      "  [  0   7]]\n",
      "\n",
      " [[285   0]\n",
      "  [  0   8]]\n",
      "\n",
      " [[284   0]\n",
      "  [  0   9]]\n",
      "\n",
      " [[281   0]\n",
      "  [  0  12]]\n",
      "\n",
      " [[285   2]\n",
      "  [  0   6]]]\n",
      "0.9829351535836177\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test)\n",
    "yhat = []\n",
    "for i in range(len(result)):\n",
    "    yhat.append(np.argmax(result[i]))\n",
    "print(multilabel_confusion_matrix(y_test, yhat))\n",
    "print(accuracy_score(y_test, yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
